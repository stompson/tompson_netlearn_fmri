{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLM Z-Score Analysis\n",
    "=====================================\n",
    "\n",
    "This script gets z-scores and p-values for the Schaefer atlas nodes by\n",
    "\n",
    "1.  loading the second-level GLM z-maps for each contrast, \n",
    "2.  calculating the average value for each node in the Schaefer atlas, \n",
    "3.  computing the z-score and p-values for each node in the Schaefer atlas, and saving the z-scores and p-values into a new npz file.\n",
    "\n",
    "# Get hub activation for social and non-social tasks\n",
    "\n",
    "1. Load subject info (cond order list) and atlas info\n",
    "2. Get dict of hubs with ROI indices\n",
    "3. Create mask for each set of hubs that you want to extract average activation from\n",
    "4. Load transition versus non-transition nii file for each task\n",
    "5. Extract average activation in mask for each set of hubs\n",
    "6. Loop over each subject & task and fill empty pandas dataframe\n",
    "7. Save pandas df as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Importing Packages\n"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "import scipy.stats as ss\n",
    "import os\n",
    "from os.path import join as opj\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nilearn import image, plotting, input_data\n",
    "import nibabel as nb\n",
    "from mne.stats import fdr_correction\n",
    "from nistats import thresholding\n",
    "from random import shuffle\n",
    "import glob\n",
    "\n",
    "print('Done Importing Packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set data paths\n"
     ]
    }
   ],
   "source": [
    "# Change to directory where you saved the data\n",
    "home_path1 = '/Users/steventompson/Git/tompson_netlearn_fmri'\n",
    "home_path = '/Users/steventompson/Dropbox/Research_Projects/Bassett_Statistical_Learning/fMRI_Study'\n",
    "\n",
    "data_dir = opj(home_path,'data')\n",
    "template_dir = '/Users/steventompson/Git/tompson_netlearn_fmri/data/brain_atlas'\n",
    "path_InpData = opj(data_dir,'Subject_Data','netLearn_glm','firstLevel')\n",
    "path_zData = opj(home_path1,'data','netLearn_ppi_zscores')\n",
    "path_OutpData = opj(home_path1,'data','glm_means')\n",
    "path_Figures = opj(home_path,'figures','component_figs') # folder to put figures\n",
    "\n",
    "\n",
    "for path in [path_OutpData, path_Figures]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path does not exist, creating {}'.format(path))\n",
    "        os.makedirs(path)\n",
    "\n",
    "print('Set data paths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 26 subjects\n"
     ]
    }
   ],
   "source": [
    "subj_links=pd.read_csv('{}/data/subj_data/netLearn_IDs_26subjs.csv'.format(home_path1))\n",
    "\n",
    "bad_subjs = ['SNL_001','SNL_004','SNL_028']\n",
    "subjs = [s for s in subj_links.loc[:,'scanID'].tolist() if s not in bad_subjs]\n",
    "#subjs.reverse()\n",
    "n_subjs = len(subjs)\n",
    "print('We have %d subjects' % (n_subjs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nID</th>\n",
       "      <th>nVal</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>nVox</th>\n",
       "      <th>Hemisphere</th>\n",
       "      <th>System</th>\n",
       "      <th>System7</th>\n",
       "      <th>MedialLateral</th>\n",
       "      <th>AnteriorPosterior</th>\n",
       "      <th>VentralDorsal</th>\n",
       "      <th>ROI_label</th>\n",
       "      <th>ns_ROI_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-35</td>\n",
       "      <td>-62</td>\n",
       "      <td>-17</td>\n",
       "      <td>309</td>\n",
       "      <td>LH</td>\n",
       "      <td>VisCent</td>\n",
       "      <td>Vis</td>\n",
       "      <td>Lateral_LH</td>\n",
       "      <td>Posterior</td>\n",
       "      <td>Ventral</td>\n",
       "      <td>Fusiform_L</td>\n",
       "      <td>Fusiform_L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-23</td>\n",
       "      <td>-73</td>\n",
       "      <td>-10</td>\n",
       "      <td>426</td>\n",
       "      <td>LH</td>\n",
       "      <td>VisCent</td>\n",
       "      <td>Vis</td>\n",
       "      <td>Lateral_LH</td>\n",
       "      <td>Posterior</td>\n",
       "      <td>Ventral</td>\n",
       "      <td>Fusiform_L</td>\n",
       "      <td>Fusiform_L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-36</td>\n",
       "      <td>-81</td>\n",
       "      <td>-16</td>\n",
       "      <td>357</td>\n",
       "      <td>LH</td>\n",
       "      <td>VisCent</td>\n",
       "      <td>Vis</td>\n",
       "      <td>Lateral_LH</td>\n",
       "      <td>Posterior</td>\n",
       "      <td>Ventral</td>\n",
       "      <td>Fusiform_L</td>\n",
       "      <td>Fusiform_L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-17</td>\n",
       "      <td>-86</td>\n",
       "      <td>-15</td>\n",
       "      <td>320</td>\n",
       "      <td>LH</td>\n",
       "      <td>VisCent</td>\n",
       "      <td>Vis</td>\n",
       "      <td>Medial</td>\n",
       "      <td>Posterior</td>\n",
       "      <td>Ventral</td>\n",
       "      <td>Lingual_L</td>\n",
       "      <td>Lingual_L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-24</td>\n",
       "      <td>-97</td>\n",
       "      <td>-12</td>\n",
       "      <td>531</td>\n",
       "      <td>LH</td>\n",
       "      <td>VisCent</td>\n",
       "      <td>Vis</td>\n",
       "      <td>Lateral_LH</td>\n",
       "      <td>Posterior</td>\n",
       "      <td>Ventral</td>\n",
       "      <td>Occipital_Inf_L</td>\n",
       "      <td>Occipital_Inf_L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  nID  nVal   x   y   z  nVox Hemisphere   System System7  \\\n",
       "0           0    0     1 -35 -62 -17   309         LH  VisCent     Vis   \n",
       "1           1    1     2 -23 -73 -10   426         LH  VisCent     Vis   \n",
       "2           2    2     3 -36 -81 -16   357         LH  VisCent     Vis   \n",
       "3           3    3     4 -17 -86 -15   320         LH  VisCent     Vis   \n",
       "4           4    4     5 -24 -97 -12   531         LH  VisCent     Vis   \n",
       "\n",
       "  MedialLateral AnteriorPosterior VentralDorsal        ROI_label  \\\n",
       "0    Lateral_LH         Posterior       Ventral       Fusiform_L   \n",
       "1    Lateral_LH         Posterior       Ventral       Fusiform_L   \n",
       "2    Lateral_LH         Posterior       Ventral       Fusiform_L   \n",
       "3        Medial         Posterior       Ventral        Lingual_L   \n",
       "4    Lateral_LH         Posterior       Ventral  Occipital_Inf_L   \n",
       "\n",
       "      ns_ROI_label  \n",
       "0       Fusiform_L  \n",
       "1       Fusiform_L  \n",
       "2       Fusiform_L  \n",
       "3        Lingual_L  \n",
       "4  Occipital_Inf_L  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load schaefer mask\n",
    "sch_filename='{}/schaefer400_harvard_oxford_2mm_mni_17network.nii.gz'.format(template_dir)\n",
    "schaefer_mask=nb.load(sch_filename)\n",
    "\n",
    "#load schaefer atlas info\n",
    "schaefer_atlas=pd.read_csv('{}/s400ho_netLearn_2mm.csv'.format(template_dir))\n",
    "\n",
    "schaefer_atlas=schaefer_atlas.fillna('Uncertain')\n",
    "schaefer_atlas.loc[schaefer_atlas['System']=='Uncertain','System']='Subcortical'\n",
    "\n",
    "schaefer_atlas.loc[[402,407],'System']='Hippocampus'\n",
    "schaefer_atlas.loc[[402,407],'System7']='Hippocampus'\n",
    "\n",
    "sch_names=np.unique(schaefer_atlas['System'])\n",
    "sch_nums=[int(np.where(sch_names==label)[0]) for label in schaefer_atlas['System']]\n",
    "\n",
    "\n",
    "schaefer_atlas.loc[schaefer_atlas['System7']=='Uncertain','System7']='Subcortical'\n",
    "sch7_names=np.unique(schaefer_atlas['System7'])\n",
    "sch7_nums=[int(np.where(sch7_names==label)[0]) for label in schaefer_atlas['System7']]\n",
    "\n",
    "net_coords=np.array(schaefer_atlas.loc[:,['x','y','z']])\n",
    "net_cols=['black']*len(net_coords)\n",
    "\n",
    "n_node = len(sch_nums)\n",
    "triu_ix, triu_iy = np.triu_indices(n_node, k=1)\n",
    "n_conn = len(triu_ix)\n",
    "\n",
    "n_perm = 500\n",
    "\n",
    "schaefer_atlas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_links.loc[:,'nsFile']='NA'\n",
    "subj_links.loc[:,'socFile']='NA'\n",
    "for subj in subj_links['pID']:\n",
    "    cond=subj_links.loc[subj_links['pID']==subj,'CondNum'].tolist()[0]\n",
    "    scanID=subj_links.loc[subj_links['pID']==subj,'scanID'].tolist()[0]\n",
    "    if cond==1:\n",
    "        nsFile='{}_task1_Transition_z_map.nii.gz'.format(scanID)\n",
    "        socFile='{}_task2_Transition_z_map.nii.gz'.format(scanID)\n",
    "    else:\n",
    "        nsFile='{}_task2_Transition_z_map.nii.gz'.format(scanID)\n",
    "        socFile='{}_task1_Transition_z_map.nii.gz'.format(scanID)\n",
    "    subj_links.loc[subj_links['pID']==subj,'nsFile']=nsFile\n",
    "    subj_links.loc[subj_links['pID']==subj,'socFile']=socFile\n",
    "    \n",
    "ns_filenames=subj_links['nsFile'].values\n",
    "soc_filenames=subj_links['socFile'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Tasks- Global Connectivity\n",
      "10 significant positive ROIs in a priori regions\n",
      "\n",
      "Social versus Non-Social- Global Connectivity\n",
      "6 significant positive ROIs in a priori regions\n",
      "\n",
      "Social versus Non-Social- Global Connectivity\n",
      "11 significant positive ROIs in a priori regions\n",
      "DG Hubs: Column ids for dmPFC_L= [165, 174]\n",
      "DG Hubs: Column ids for vmPFC_L= [160]\n",
      "DG Hubs: Column ids for TPJ_R= [244]\n",
      "DG Hubs: Column ids for Hippocampus_R= [407]\n",
      "DG Hubs: Column ids for combhubs= [44, 160, 165, 174, 244, 370, 376, 378, 402, 407]\n",
      "DG Hubs: Column ids for TPJ_L= [44]\n",
      "DG Hubs: Column ids for Hippocampus_L= [402]\n",
      "DG Hubs: Column ids for Hippocampus= [402, 407]\n",
      "DG Hubs: Column ids for dmPFC_R= [370, 376, 378]\n",
      "\n",
      "Soc Hubs: Column ids for TPJ_R= [262, 394, 396, 397]\n",
      "Soc Hubs: Column ids for diffhubs= [85, 172, 262, 394, 396, 397]\n",
      "Soc Hubs: Column ids for TPJ_L= [85, 172]\n",
      "\n",
      "NS Hubs: Column ids for lPFC_L= [182]\n",
      "NS Hubs: Column ids for dmPFC_L= [165, 177]\n",
      "NS Hubs: Column ids for Frontal_Inf_Orb_R= [308]\n",
      "NS Hubs: Column ids for diffhubs_ns= [165, 177, 182, 304, 308, 310, 332, 370, 371, 376, 378]\n",
      "NS Hubs: Column ids for Frontal_Inf_Oper_R= [332]\n",
      "NS Hubs: Column ids for Frontal_Inf_Orb_L= [182]\n",
      "NS Hubs: Column ids for dmPFC_R= [310, 370, 371, 376, 378]\n",
      "NS Hubs: Column ids for lPFC_R= [308, 332, 304]\n",
      "NS Hubs: Column ids for Frontal_Inf_Tri_R= [304]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "list1=['combData','diffData','nonSocData','SocData']\n",
    "list1_labels=['All Tasks','Social versus Non-Social','Non-Social Task','Social Task']\n",
    "list2=['nodestr']\n",
    "list2_labels=['Global']\n",
    "\n",
    "\n",
    "apriori_names=['dmPFC_L','vmPFC_L','PCC_L','Hippocampus_L','TPJ_L',\n",
    "               'dmPFC_R','vmPFC_R','PCC_R','Hippocampus_R','TPJ_R',\n",
    "               'Frontal_Inf_Oper_L','Frontal_Inf_Orb_L','Frontal_Inf_Tri_L',\n",
    "               'Frontal_Inf_Oper_R','Frontal_Inf_Orb_R','Frontal_Inf_Tri_R',\n",
    "               'Amygdala_L','Amygdala_R',\n",
    "               'Ventral_Striatum_L','Caudate_L',\n",
    "               'Ventral_Striatum_R','Caudate_R']\n",
    "\n",
    "\n",
    "\n",
    "def identify_hubs1(ix,iy,thresh=True,apriori=True,flip=False,alpha=0.05):\n",
    "    xx=list2[ix]\n",
    "    yy=list1[iy]\n",
    "    data=np.load('{}/netLearn_{}_zscores_26subjs_{}.npz'.format(path_zData,yy,xx))\n",
    "    zMat=data['zMat']\n",
    "    pMat=data['pMat']\n",
    "    #pMat=np.multiply(data['pMat'],2)\n",
    "    \n",
    "    if flip:\n",
    "        zMat=np.multiply(zMat,-1)\n",
    "    \n",
    "    # Set nonsignificant values to zero using FDR correction\n",
    "    if thresh:\n",
    "        reject_fdr,pval_fdr=fdr_correction(pMat,alpha)\n",
    "        zMat=np.multiply(zMat,reject_fdr)\n",
    "\n",
    "    title='{}- {} Connectivity'.format(list1_labels[iy],list2_labels[ix])\n",
    "    sig_ix=np.where(zMat>0)[0]\n",
    "    sig_dic={}\n",
    "    sig_vec=np.zeros(zMat.shape)\n",
    "    if apriori:\n",
    "        sig_ix=[x for x in sig_ix if schaefer_atlas.loc[x,'ns_ROI_label'] in apriori_names]\n",
    "        for i,x in enumerate(apriori_names):\n",
    "            sig_dic[x]=[ix for ix in sig_ix if schaefer_atlas.loc[ix,'ns_ROI_label']==x]\n",
    "            sig_dic=dict((k, v) for k, v in sig_dic.iteritems() if v)\n",
    "\n",
    "    sig_vec[sig_ix]=1\n",
    "        \n",
    "    print('')\n",
    "    print(title)\n",
    "    print('{} significant positive ROIs in a priori regions'.format(len(sig_ix)))\n",
    "    return sig_ix,sig_vec,sig_dic\n",
    "    \n",
    "sigvals_comb,sigvec_comb,sigdic_comb=identify_hubs1(0,0,alpha=0.025)\n",
    "signames_comb=schaefer_atlas.loc[sigvals_comb,'ns_ROI_label']\n",
    "\n",
    "sigvals_diff,sigvec_diff,sigdic_diff=identify_hubs1(0,1,alpha=0.025)\n",
    "signames_diff=schaefer_atlas.loc[sigvals_diff,'ns_ROI_label']\n",
    "\n",
    "\n",
    "sigvals_diff_ns,sigvec_diff_ns,sigdic_diff_ns=identify_hubs1(0,1,flip=True,alpha=0.025)\n",
    "signames_diff_ns=schaefer_atlas.loc[sigvals_diff_ns,'ns_ROI_label']\n",
    "\n",
    "sigdic_comb['Hippocampus']=[402,407]\n",
    "sigdic_comb['combhubs']=sigvals_comb\n",
    "sigdic_diff['diffhubs']=sigvals_diff\n",
    "sigdic_diff_ns['diffhubs_ns']=sigvals_diff_ns\n",
    "\n",
    "lpfc_l_vals=[sigdic_diff_ns[key] for key in sigdic_diff_ns.keys() if 'Frontal' in key and '_L' in key]\n",
    "sigdic_diff_ns['lPFC_L']=[item for sublist in lpfc_l_vals for item in sublist]\n",
    "lpfc_r_vals=[sigdic_diff_ns[key] for key in sigdic_diff_ns.keys() if 'Frontal' in key and '_R' in key]\n",
    "sigdic_diff_ns['lPFC_R']=[item for sublist in lpfc_r_vals for item in sublist]\n",
    "\n",
    "\n",
    "for x in sigdic_comb.keys():\n",
    "    print('DG Hubs: Column ids for {}= {}'.format(x,sigdic_comb[x]))\n",
    "    \n",
    "print('')\n",
    "for x in sigdic_diff.keys():\n",
    "    print('Soc Hubs: Column ids for {}= {}'.format(x,sigdic_diff[x]))\n",
    "    \n",
    "print('')\n",
    "for x in sigdic_diff_ns.keys():\n",
    "    print('NS Hubs: Column ids for {}= {}'.format(x,sigdic_diff_ns[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating 26 images\n",
      "Extracting values from nii image\n",
      "Matrix created with shape (26, 410)\n"
     ]
    }
   ],
   "source": [
    "def get_atlas_means(flist,fpath,atlas_path):\n",
    "    fnames=[opj(fpath,f) for f in flist]\n",
    "    print('Concatenating {} images'.format(len(fnames)))\n",
    "    all_imgs=image.concat_imgs(fnames,memory='nilearn_cache',memory_level=1)\n",
    "    masker = input_data.NiftiLabelsMasker(atlas_path,\n",
    "                                           detrend=False, \n",
    "                                           standardize=False, \n",
    "                                           low_pass=None, high_pass=None, \n",
    "                                           t_r=1,\n",
    "                                           memory='nilearn_cache', memory_level=1); #verbose=2 by default nothing should be printed\n",
    "\n",
    "    print('Extracting values from nii image')\n",
    "    all_ts = masker.fit_transform(all_imgs).squeeze()\n",
    "\n",
    "    print('Matrix created with shape {}'.format(all_ts.shape))\n",
    "    return all_ts\n",
    "\n",
    "node_means=get_atlas_means(ns_filenames,path_InpData,sch_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting subject averages for diffhubs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "#adj_mat is 2-d matrix with n_subj x n_node shape\n",
    "#row_ix is a list of indices to keep for the rows\n",
    "#col_ix is a list of indices to keep for the columns\n",
    "def get_means(roi_mat,row_ix,col_ix):\n",
    "    #cfg_mat is a 3D n_subjs x n_perm x n_conn np array\n",
    "    #row_ix is a list of the row indices to include in the means to extract\n",
    "    #col_ix is a list of the column indices to include in the means to extract\n",
    "    subdata=roi_mat[row_ix,:]\n",
    "    subdata=subdata[:,col_ix]\n",
    "    rowMeans=np.mean(subdata,axis=(-1))\n",
    "    return rowMeans\n",
    "\n",
    "def get_subhub_means(roi_mat,col_dict,col_id):\n",
    "    #roi_cfg is a 2D n_subjs x n_conn np array\n",
    "    #nulll_cfg is a 3D n_subjs x n_perm x n_conn np array\n",
    "    #row_id is a string that matches a key in the row_dict (or is 'all' which will get global connectivity)\n",
    "    #row_dict is a dictionary with keys matching a priori hubs and row indices for each hub\n",
    "    #col_id is a string that matches a key in the col_dict (or is 'all' which will get global connectivity)\n",
    "    #col_dict is a dictionary with keys matching a priori hubs and column indices for each hub\n",
    "    #thresh is a boolean determining whether to set non-significant z-scores to zero\n",
    "    print('')    \n",
    "    if col_id=='all':\n",
    "        col_ix=range(410)\n",
    "    else:\n",
    "        col_ix=col_dict[col_id]\n",
    "        \n",
    "    print('Getting subject averages for {}'.format(col_id))\n",
    "    subj_vec=get_means(roi_mat,range(roi_mat.shape[0]),col_ix)\n",
    "    return subj_vec\n",
    "\n",
    "test=get_subhub_means(node_means,sigdic_diff,'diffhubs')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TPJ_R', 'diffhubs', 'TPJ_L']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigdic_diff.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.84835539,  0.82312892,  2.1707546 , ...,  0.29755954,\n",
       "         0.18091637,  0.43706501],\n",
       "       [ 1.71391192,  0.49677069,  1.62133033, ...,  0.58582973,\n",
       "         0.92263893,  0.22388916],\n",
       "       [ 2.36524565,  3.15082657,  2.0522868 , ..., -0.07091223,\n",
       "         0.26890892,  0.12084748],\n",
       "       ...,\n",
       "       [ 1.02474884,  1.28661817,  1.33643999, ..., -0.66685007,\n",
       "        -1.61041167, -0.41039404],\n",
       "       [ 1.03882852,  2.09557063,  1.82848311, ..., -1.68425837,\n",
       "        -1.32958808, -1.10583156],\n",
       "       [ 0.8475027 ,  1.10025549,  0.95867425, ..., -0.71877035,\n",
       "        -0.75124414, -1.59969763]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_means[range(26),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_node_zscores(node_vec,null_vec,savename,thresh=False):\n",
    "    zMat=np.zeros(node_vec.shape)\n",
    "    pMat=zMat.copy()\n",
    "    n_node=node_vec.shape[0]\n",
    "    for x in range(n_node):\n",
    "        if x==0:\n",
    "            print('Working on node 1',end='')\n",
    "        elif (x+1)%(int(n_node/10))==0:\n",
    "            print('...{}'.format(x+1),end='')\n",
    "        elif (x+1)==n_node:\n",
    "            print('')\n",
    "        pval=ss.percentileofscore(null_vec[:,x],node_vec[x])/100\n",
    "        zMat[x]=ss.norm.ppf(pval)\n",
    "        zMat[zMat == -inf] = -4\n",
    "        zMat[zMat == inf] = 4\n",
    "        if pval<0.5:\n",
    "            pMat[x]=pval\n",
    "        else:\n",
    "            pMat[x]=1-pval\n",
    "    print('...')\n",
    "    print('Computed zMat and pMat for {} nodes'.format(n_node))\n",
    "    #np.array([(ss.percentileofscore(null_mat[:,x],roi_mat[x])/100) for x in range(n_node)])\n",
    "    if thresh:\n",
    "        reject_fdr,fdr_pvals=fdr_correction(pMat,alpha=0.025)\n",
    "        n_sig=np.sum(reject_fdr)\n",
    "        print('# of significant nodes for {} is: {}'.format(col_id,n_sig))\n",
    "        zMat=np.multiply(zMat,reject_fdr)\n",
    "        pMat=fdr_pvals\n",
    "    \n",
    "    savefile='{}/netLearn_{}_zscores_{}nodes'.format(path_OutpData,savename,n_node)\n",
    "    np.savez(savefile,zMat=zMat,pMat=pMat)\n",
    "    print('Saving file to {}.npz'.format(savefile))\n",
    "    print('...')\n",
    "    return zMat,pMat\n",
    "\n",
    "def comb_func(con_name,atlas_path):\n",
    "    print('Starting extraction of z-scores for {}'.format(con_name))\n",
    "    print('...')\n",
    "    t1=get_atlas_means(path_InpData,con_name,atlas_path)\n",
    "    t2=get_atlas_means(path_NullData,con_name,atlas_path)\n",
    "    zMat,pMat=get_node_zscores(t1,t2,con_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to extract a single ROI\n",
    "def get_roi_mean(fname,atlas,roinums):\n",
    "    tdata=nb.load(fname).get_data()\n",
    "    mask=np.where(atlas==roinum,1,0)\n",
    "    roidata=np.multiply(mask,tdata)\n",
    "    roi_mean=np.sum(roidata)/np.sum(mask)\n",
    "    return roi_mean\n",
    "\n",
    "template_dir=opj('/data/jux/stompson/tools/BrainAtlases')\n",
    "\n",
    "#load schaefer mask\n",
    "schaefer_file='{}/Schaefer2018/schaefer400_harvard_oxford_2mm_mni_17network.nii.gz'.format(template_dir)\n",
    "schaefer_mask=nb.load(schaefer_file)\n",
    "\n",
    "roi_file='{}/Schaefer2018/s400ho_91roi_atlas_2mm_mni_17network.nii.gz'.format(template_dir)\n",
    "roi_mask=nb.load(roi_file)\n",
    "\n",
    "schaefer_data=schaefer_mask.get_data()\n",
    "roi_data=roi_mask.get_data()\n",
    "\n",
    "#load schaefer atlas info\n",
    "schaefer_atlas=pd.read_pickle('{}/s400ho_ns_netLearn_2mm.pickle'.format(template_dir))\n",
    "roi_atlas=pd.read_pickle('{}/s400ho_91_neurosynth_roi_netLearn_2mm.pickle'.format(template_dir))\n",
    "\n",
    "\n",
    "schaefer_atlas=schaefer_atlas.fillna('Uncertain')\n",
    "sch_names=np.unique(schaefer_atlas['System'])\n",
    "sch_nums=[int(np.where(sch_names==label)[0]) for label in schaefer_atlas['System']]\n",
    "\n",
    "roi_names=np.unique(roi_atlas['ROI'])\n",
    "roi_nums=[int(np.where(roi_names==label)[0]) for label in roi_atlas['ROI']]\n",
    "\n",
    "n_node = len(sch_nums)\n",
    "triu_ix, triu_iy = np.triu_indices(n_node, k=1)\n",
    "n_conn = len(triu_ix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def load_subj_map(subj,task):\n",
    "    \n",
    "def subj_activation(task):\n",
    "    df=pd.DataFrame()\n",
    "    \n",
    "    # load activation maps\n",
    "    print('')\n",
    "    glm_map=load_mat('netLearn_{}_transition_PPI_26subjs.npz'.format(task))\n",
    "    print('')\n",
    "    null_mat=load_null_mat('netLearn_{}_nulldata_transition_PPI_26subjs.npz'.format(task))\n",
    "    \n",
    "    for a in ['combhubs','Hippocampus','Hippocampus_L','Hippocampus_R']:\n",
    "    #for a in ['Hippocampus','Hippocampus_L','Hippocampus_R','Frontal_Inf_Orb_L','Frontal_Inf_Tri_R','dmPFC_L','dmPFC_R','vmPFC_L']:\n",
    "            colname='{}_global'.format(a)\n",
    "            sub_z,sub_p=get_subhub_zscores(ppi_mat,null_mat,a,'all',sigdic_comb,sigdic_comb)\n",
    "            df[colname]=sub_z\n",
    "            print('')\n",
    "\n",
    "    #for a in ['PCC_L','TPJ_L','TPJ_R']:\n",
    "    for a in ['diffhubs','TPJ_L','TPJ_R']:\n",
    "            colname='{}_global'.format(a)\n",
    "            sub_z,sub_p=get_subhub_zscores(ppi_mat,null_mat,a,'all',sigdic_diff,sigdic_diff)\n",
    "            df[colname]=sub_z\n",
    "            print('')\n",
    "            \n",
    "    #for a in ['PCC_L','TPJ_L','TPJ_R']:\n",
    "    for a in ['diffhubs_ns','dmPFC_L','dmPFC_R','lPFC_L','lPFC_R']:\n",
    "            colname='{}_global'.format(a)\n",
    "            sub_z,sub_p=get_subhub_zscores(ppi_mat,null_mat,a,'all',sigdic_diff_ns,sigdic_diff_ns)\n",
    "            df[colname]=sub_z\n",
    "            print('')\n",
    "    \n",
    "    df.to_csv('{}/netLearn_{}Data_zscores_26subjs_sighubs_nodestr.csv'.format(path_OutpData,task))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
