{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Task Data\n",
    "This script takes the raw response data from the PsychoPy program that presented the task to participants in the MRI scanner and creates a trial-level dataframe with all the trials, response time, accuracy, and trial type information. It also excludes trials that we won't be using in our analysis, such as outliers, incorrect responses, and rotated trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Set up environment and get task metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm(list=ls())\n",
    "library(reshape2)\n",
    "library(plyr)\n",
    "\n",
    "##Set path to CSV files with raw task data\n",
    "data_dir<-\"/Users/steventompson/Git/tompson_netlearn_fmri/data/subj_data/raw_task_data\"\n",
    "\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "### Step 1: Get metadata for each file in data folder ###\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "\n",
    "\n",
    "##List the files in the data folder\n",
    "filenames <- list.files(data_dir)\n",
    "\n",
    "metaData<-data.frame(\"pID\"=rep(NA,length(filenames)),\"Cond\"=rep(NA,length(filenames)),\"Run\"=rep(NA,length(filenames)))\n",
    "for(i in 1:length(filenames)){\n",
    "  file1<-strsplit(filenames[i],\"_\")\n",
    "  metaData$pID[i]<-as.numeric(gsub(\"subj\",\"\",file1[[1]][[1]]))\n",
    "  metaData$Cond[i]<-gsub(\"log\",\"\",file1[[1]][[2]])\n",
    "  metaData$Run[i]<-as.numeric(gsub(\"run|.csv\",\"\",file1[[1]][[3]]))\n",
    "  metaData$StartTime[i]<-file.info(filenames[i])$mtime\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Load and merge subject task data into single dataframe\n",
    "Loop over each subject and run and load the raw task data file, then add trial-level data to dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "########################################################################################################\n",
    "### Step 2: Combine each run's data into single file ###\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "\n",
    "##Combine the data files by row\n",
    "##Useful for when the columns are identical and you're just trying to merge cases\n",
    "#combined <- do.call(\"rbind\", lapply(filenames, read.csv, header = TRUE))\n",
    "\n",
    "#create empty data frame to add data to\n",
    "combData<-data.frame()\n",
    "\n",
    "for(i in 1:length(filenames)){\n",
    "  #set file name and read the data for that file into R\n",
    "  fileName<-filenames[i]\n",
    "  subData<-read.csv(paste(data_dir,fileName,sep=\"/\"),header=T,stringsAsFactors=F)\n",
    "\n",
    "  #Count total number of missing values\n",
    "  metaData$missedResp[i]<-sum(as.character(subData$resp_raw)==\"'NA'\")\n",
    "  #as.character(gsub(\"[']\",\"\",subData$resp_raw))\n",
    "  \n",
    "  #Add condition variable and remove extra rows\n",
    "  subData$Cond<-metaData$Cond[i]\n",
    "  subData<-subset(subData,subset=!is.na(subData$trialNum))\n",
    "  #append subData to end of the full data file\n",
    "  combData<-rbind(combData,subData)\n",
    "}\n",
    "\n",
    "#Convert variables to remove unnecessary characters and fix data types\n",
    "combData$pID<-as.numeric(combData$pID)\n",
    "combData$resp_raw<-gsub(\"[']\",\"\",combData$resp_raw) #remove unnecessary characters\n",
    "combData$rt_raw<-as.numeric(gsub(\"[']\",\"\",combData$rt_raw)) #remove unnecessary characters\n",
    "combData$rt_raw<-combData$rt_raw*1000 #change RT to milliseconds\n",
    "\n",
    "#remove unnecessary variables\n",
    "rm(i)\n",
    "rm(file1)\n",
    "rm(subData)\n",
    "rm(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check summary data for each subject to determine who to exclude\n",
    "\n",
    "print('# of Trials')\n",
    "print((tapply(combData$walk,combData$pID,function(i){sum(!is.na(i),na.rm=T)}))) #number of trials\n",
    "print('')\n",
    "print('# of Trials with No Response')\n",
    "print((tapply(combData$rt_raw,combData$pID,function(i){sum(is.na(i),na.rm=T)}))) #number of trials with no response\n",
    "print('')\n",
    "print('Percent Correct Trials')\n",
    "print((tapply(combData$correct_raw,combData$pID,function(i){sum(i,na.rm=T)/2000}))) #percent correct trials\n",
    "\n",
    "\n",
    "#[1] \"# of Trials\"\n",
    "#   1    2    4    5    8    9   11   12   13   15   16   18   19   20   21   23 \n",
    "#2000 2000 2000 2000 2000 2000 2000 2000 1000 2000 2000 2000 2000 2000 2000 2000 \n",
    "#  24   25   26   27   28   29   30   31   32   33   34   35   36   37   39 \n",
    "#2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 \n",
    "#[1] \"\"\n",
    "#[1] \"# of Trials with No Response\"\n",
    "#   1    2    4    5    8    9   11   12   13   15   16   18   19   20   21   23 \n",
    "#  98   45   35   55   86   69   82   56   32  314   54   81   77  669   32  274 \n",
    "#  24   25   26   27   28   29   30   31   32   33   34   35   36   37   39 \n",
    "#  65   38   61   59 1339   34   56   88   82   50  273   88   41  334   73 \n",
    "#[1] \"\"\n",
    "#[1] \"Percent Correct Trials\"\n",
    "#     1      2      4      5      8      9     11     12     13     15     16 \n",
    "#0.7540 0.9230 0.8975 0.9010 0.9005 0.9085 0.8535 0.8845 0.3640 0.6020 0.9025 \n",
    "#    18     19     20     21     23     24     25     26     27     28     29 \n",
    "#0.8705 0.8610 0.4290 0.9580 0.7220 0.8960 0.9280 0.7190 0.8875 0.2390 0.9295 \n",
    "#    30     31     32     33     34     35     36     37     39 \n",
    "#0.8950 0.8590 0.7935 0.9025 0.7565 0.8320 0.8385 0.6340 0.9120 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Identify transition and non-transition trials\n",
    "Add variable for node type to each trial based on the location of the image in the network and the preceding trial(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "########################################################################################################\n",
    "### Step 3: Add variables to each trial ###\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "#count number of times trial presented in last 10 trials & number of trials since image last shown\n",
    "#add transition groupings\n",
    "#0<->14, 4<->5, 9<->10\n",
    "#If two trials in a row are 0->14, 14->0, 4->5, 5->4, 9->10, 10->9\n",
    "#set first trial as pre-transition node and second trial as transition node \n",
    "\n",
    "\n",
    "#Split into NS and Soc datasets\n",
    "\n",
    "combDataNS<-subset(combData,subset=combData$Cond==\"NS\")\n",
    "combDataSoc<-subset(combData,subset=combData$Cond==\"Soc\")\n",
    "\n",
    "\n",
    "#set default values\n",
    "combDataNS$pre<-0\n",
    "combDataNS$transition<-0\n",
    "combDataNS$grouping<-\"x\"\n",
    "\n",
    "for(subj in unique(combDataNS$pID)){\n",
    "  subjData<-combDataNS[combDataNS$pID==subj,]\n",
    "  for(trial in subjData$trialNum){\n",
    "    node<-subjData$walk[subjData$trialNum==trial]\n",
    "    \n",
    "    #Create groupings\n",
    "    if(trial>1){\n",
    "      pre_node<-subjData$walk[subjData$trialNum==(trial-1)]\n",
    "      if((pre_node==0&node==9)|(pre_node==9&node==0)|(pre_node==4&node==5)|(pre_node==5&node==4)){\n",
    "        combDataNS$pre[combDataNS$pID==subj & combDataNS$trialNum==(trial-1)] <- 1\n",
    "        combDataNS$transition[combDataNS$pID==subj & combDataNS$trialNum==trial] <- 1\n",
    "        if(combDataNS$transition[combDataNS$pID==subj & combDataNS$trialNum==trial]==1 & combDataNS$transition[combDataNS$pID==subj & combDataNS$trialNum==(trial-1)]!=1){\n",
    "          combDataNS$grouping[combDataNS$pID==subj & combDataNS$trialNum==(trial-1)] <- \"x\"\n",
    "          combDataNS$grouping[combDataNS$pID==subj & combDataNS$trialNum==trial] <- \"transition\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "#set default values\n",
    "combDataSoc$pre<-0\n",
    "combDataSoc$transition<-0\n",
    "combDataSoc$grouping<-\"x\"\n",
    "\n",
    "for(subj in unique(combDataSoc$pID)){\n",
    "  subjData<-combDataSoc[combDataSoc$pID==subj,]\n",
    "  for(trial in subjData$trialNum){\n",
    "    node<-subjData$walk[subjData$trialNum==trial]\n",
    "    \n",
    "    #Create groupings\n",
    "    if(trial>1){\n",
    "      pre_node<-subjData$walk[subjData$trialNum==(trial-1)]\n",
    "      if((pre_node==0&node==9)|(pre_node==9&node==0)|(pre_node==4&node==5)|(pre_node==5&node==4)){\n",
    "        combDataSoc$pre[combDataSoc$pID==subj & combDataSoc$trialNum==(trial-1)] <- 1\n",
    "        combDataSoc$transition[combDataSoc$pID==subj & combDataSoc$trialNum==trial] <- 1\n",
    "        if(combDataSoc$transition[combDataSoc$pID==subj & combDataSoc$trialNum==trial]==1 & combDataSoc$transition[combDataSoc$pID==subj & combDataSoc$trialNum==(trial-1)]!=1){\n",
    "          combDataSoc$grouping[combDataSoc$pID==subj & combDataSoc$trialNum==(trial-1)] <- \"x\"\n",
    "          combDataSoc$grouping[combDataSoc$pID==subj & combDataSoc$trialNum==trial] <- \"transition\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "#Clean up\n",
    "rm(node,pre_node,subj,trial,subjData)\n",
    "\n",
    "combData<-rbind(combDataNS,combDataSoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data\n",
    "savepath<-\"/Users/steventompson/Git/tompson_netlearn_fmri/data/subj_data\"\n",
    "savename<-\"tompson_netlearn_fmri_trial_data.csv\"\n",
    "\n",
    "write.csv(combData,paste(savepath,savename,sep=\"/\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steven Tompson | 2019"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
