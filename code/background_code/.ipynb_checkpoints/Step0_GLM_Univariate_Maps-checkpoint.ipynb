{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Brain Activation Analyses\n",
    "\n",
    "This script loads preprocessed nii files for each task and computes a GLM to test activation differences for transition versus non-transition nodes and social versus non-social networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division,print_function\n",
    "\n",
    "import os\n",
    "from os import mkdir, path, getcwd\n",
    "from os.path import join as opj\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nibabel as nb\n",
    "\n",
    "from nilearn import plotting\n",
    "from nilearn.image import mean_img\n",
    "from nilearn.masking import compute_epi_mask\n",
    "\n",
    "from nistats.first_level_model import FirstLevelModel\n",
    "from nistats.reporting import plot_design_matrix, plot_contrast_matrix\n",
    "from nistats.design_matrix import make_first_level_design_matrix\n",
    "\n",
    "# write directory\n",
    "\n",
    "home_path = '/Users/steventompson/Git/tompson_netlearn_fmri'\n",
    "data_dir = opj(home_path,'data')\n",
    "\n",
    "path_InpData = opj(home_path,'subjs_glm') # folder containing the preprocessed subject images\n",
    "path_l1Data = opj(data_dir,'Subject_Data','netLearn_glm','firstLevel') # folder to put results maps\n",
    "path_l2Data = opj(data_dir,'Subject_Data','netLearn_glm','secondLevel') # folder to put results maps\n",
    "template_dir = opj(data_dir,'brain_atlas') # folder with template masks and brain atlases\n",
    "\n",
    "for folder in [path_l1Data,path_l2Data]:\n",
    "    if not os.path.exists(folder):\n",
    "        print('Creating folder {}'.format(folder))\n",
    "        os.makedirs(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnifile=opj(template_dir,'MNI152_T1_2mm_brain.nii.gz')\n",
    "maskfile=opj(template_dir,'MNI152_T1_2mm_brain_mask.nii.gz')\n",
    "\n",
    "if not os.path.exists(maskfile):\n",
    "    mask=compute_epi_mask(maskfile)\n",
    "    nb.save(mask,maskfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterFile=pd.read_csv('{}/subj_data/netLearn_masterFile_26subjs.csv'.format(data_dir))\n",
    "subj_links=pd.read_csv('{}/subj_data/netLearn_IDs_26subjs.csv'.format(data_dir))\n",
    "\n",
    "bad_subjs = ['SNL_001','SNL_004','SNL_028']\n",
    "subjs = [s for s in subj_links.loc[:,'scanID'].tolist() if s not in bad_subjs]\n",
    "n_subjs = len(subjs)\n",
    "print('We have %d subjects' % (n_subjs))\n",
    "\n",
    "#Create list of run IDs\n",
    "runs=['run1','run2','run3','run4','run5','run6','run7','run8','run9','run10']\n",
    "task1=['run1','run2','run3','run4','run5']\n",
    "task2=['run6','run7','run8','run9','run10']\n",
    "\n",
    "#Create run labels\n",
    "masterFile['Run']=0\n",
    "masterFile.loc[np.in1d(np.array(masterFile['trialNum']),range(200)),'Run']=1\n",
    "masterFile.loc[np.in1d(np.array(masterFile['trialNum']),range(200,400)),'Run']=2\n",
    "masterFile.loc[np.in1d(np.array(masterFile['trialNum']),range(400,600)),'Run']=3\n",
    "masterFile.loc[np.in1d(np.array(masterFile['trialNum']),range(600,800)),'Run']=4\n",
    "masterFile.loc[np.in1d(np.array(masterFile['trialNum']),range(800,1000)),'Run']=5\n",
    "\n",
    "masterFile.loc[masterFile['transition']==0,'transition']='x'\n",
    "masterFile.loc[masterFile['transition']==1,'transition']='transition'\n",
    "\n",
    "masterFile=masterFile.loc[masterFile['transition']=='transition',:]\n",
    "\n",
    "#Set experiment parameters\n",
    "tr = 1.0\n",
    "condlist=['transition']\n",
    "hmlist=['tx','ty','tz','rx','ry','rz']\n",
    "covarlist=['tx','ty','tz','rx','ry','rz','constant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step 2: First Level Analysis\n",
    "\n",
    "Analysis Steps:\n",
    "\n",
    "1. A sequence of fMRI volumes are loaded\n",
    "2. A design matrix describing all the effects related to the data is computed\n",
    "3. a mask of the useful brain volume is computed\n",
    "4. A GLM is applied to the dataset (effect/covariance,\n",
    "   then contrast estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MRI images and create design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list(subjID,task_list):\n",
    "    fpath='{}/{}/func'.format(path_InpData,subjID)\n",
    "    flist=['{}/swcad_BOLD_{}.nii.gz'.format(fpath,x) for x in task_list]\n",
    "    return flist\n",
    "\n",
    "def load_hm_data(subjID,runID):\n",
    "    conf_filename = opj(path_InpData,subjID,'func','ad_BOLD_{}.nii.gz.par'.format(runID))  #motion confounds\n",
    "    motpars = np.loadtxt(conf_filename)\n",
    "    return motpars\n",
    "\n",
    "def create_sub_design(subjID,runID,df,regs,regnames):\n",
    "    #Note: ppt in Condition #1 saw non-social task first, \n",
    "    #whereas ppt in Condition #2 saw social task first\n",
    "    pID=int(subjID[-3:])\n",
    "    rID=int(runID.replace('run',''))\n",
    "    n_scans = len(regs)\n",
    "    frame_times = np.arange(n_scans) * tr\n",
    "    subdata=df.loc[df['pID']==pID,:]\n",
    "    if int(subj_links.loc[subj_links['scanID']==subjID,'CondNum'])==1 and rID<6:\n",
    "        subdata=subdata.loc[subdata['Cond']=='NS',:]\n",
    "        subdata=subdata.loc[subdata['Run']==rID,:]\n",
    "    elif int(subj_links.loc[subj_links['scanID']==subjID,'CondNum'])==1 and rID>5:\n",
    "        subdata=subdata.loc[subdata['Cond']=='Soc',:]\n",
    "        subdata=subdata.loc[subdata['Run']==rID-5,:]\n",
    "    elif int(subj_links.loc[subj_links['scanID']==subjID,'CondNum'])==2 and rID<6:\n",
    "        subdata=subdata.loc[subdata['Cond']=='Soc',:]\n",
    "        subdata=subdata.loc[subdata['Run']==rID,:]\n",
    "    elif int(subj_links.loc[subj_links['scanID']==subjID,'CondNum'])==2 and rID>5:\n",
    "        subdata=subdata.loc[subdata['Cond']=='NS',:]\n",
    "        subdata=subdata.loc[subdata['Run']==rID-5,:]\n",
    "    trials=subdata['transition'].tolist()\n",
    "    onsets=subdata['onset_raw'].tolist()\n",
    "    durs=[1.5]*len(trials)\n",
    "    paradigm = pd.DataFrame({'trial_type': trials, 'onset': onsets,\n",
    "                             'duration': durs})\n",
    "    X1 = make_first_level_design_matrix(frame_times, paradigm,\n",
    "                                        add_regs=regs, add_reg_names=regnames,\n",
    "                                        drift_model=None,hrf_model='SPM')\n",
    "    return X1\n",
    "\n",
    "\n",
    "def get_design_matrices(subjID,runlist):\n",
    "    print('...')\n",
    "    print('Create list of design matrices')\n",
    "    print('...')\n",
    "    design_matrices=[]\n",
    "    for rr,runID in enumerate(runlist):\n",
    "        hm1=load_hm_data(subjID,runID)\n",
    "        newdf=create_sub_design(subjID,runID,masterFile,hm1,hmlist)\n",
    "        design_matrices.append(newdf)\n",
    "    return design_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute first-level General Linear Model for each subject and each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_glm(fmri_img,design_matrices,mask_file):\n",
    "    print('Step 2: Generate GLM\\n...')\n",
    "    fmri_glm = FirstLevelModel(hrf_model='SPM', drift_model=None, \n",
    "                               mask=mask_file, minimize_memory=True)\n",
    "    fmri_glm = fmri_glm.fit(fmri_img, design_matrices=design_matrices)\n",
    "    print('\\nGLM Parameters:')\n",
    "    print(fmri_glm)\n",
    "    print('')\n",
    "    return fmri_glm\n",
    "\n",
    "def pad_vector(contrast_, n_columns):\n",
    "    return np.hstack((contrast_, np.zeros(n_columns - len(contrast_))))\n",
    "\n",
    "\n",
    "def create_contrast_list(design_matrices):\n",
    "    n_columns = design_matrices[0].shape[1]\n",
    "    contrasts = {'Transition': pad_vector([1], n_columns)}\n",
    "    #print(contrasts.items())\n",
    "    return contrasts\n",
    "\n",
    "def compute_contrasts(subjID,design_matrices,fmri_glm,savename):\n",
    "    contrasts=create_contrast_list(design_matrices)\n",
    "    #contrasts=create_contrast_list(design_matrices,varlist)\n",
    "    print('Step 3: Compute contrasts\\n...')\n",
    "    print('')\n",
    "    print('Contrast list:')\n",
    "    print(contrasts.items())\n",
    "    print('')\n",
    "    print('Computing contrasts...')\n",
    "    for index, (contrast_id, contrast_val) in enumerate(contrasts.items()):\n",
    "        print('  Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(contrasts), contrast_id))\n",
    "        savefolder=path_l1Data\n",
    "        z_image_path = opj(savefolder,'{}_{}_{}_z_map.nii'.format(subjID,contrast_id,savename))\n",
    "        z_map = fmri_glm.compute_contrast(\n",
    "            contrast_val, output_type='z_score')\n",
    "        z_map.to_filename(z_image_path)\n",
    "        print('All the  results were written in {}'.format(savefolder))\n",
    "\n",
    "def compute_contrasts2(subjID,design_matrices,varlist,fmri_glm,\n",
    "                      savename,savetype='t-stat'):\n",
    "    contrasts=create_contrast_list(design_matrices)\n",
    "    #contrasts=create_contrast_list(design_matrices,varlist)\n",
    "    print('Step 3: Compute contrasts\\n...')\n",
    "    print('')\n",
    "    print('Contrast list:')\n",
    "    print(contrasts.items())\n",
    "    for index, (contrast_id, contrast_val) in enumerate(contrasts.items()):\n",
    "        print('  Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(contrasts), contrast_id))\n",
    "        savefolder=path_l1Data\n",
    "\n",
    "        if savetype=='t-stat':\n",
    "            image_path = opj(savefolder,'{}_{}_{}_t_map.nii.gz'.format(subjID,savename,contrast_id))\n",
    "            cmap = fmri_glm.compute_contrast(contrast_val, stat_type='t',output_type='stat')\n",
    "            cmap.to_filename(image_path)\n",
    "        if savetype=='z_score':\n",
    "            image_path = opj(savefolder,'{}_{}_{}_z_map.nii.gz'.format(subjID,savename,contrast_id))\n",
    "            cmap = fmri_glm.compute_contrast(contrast_val, stat_type='t',output_type='z_score')\n",
    "            cmap.to_filename(image_path)\n",
    "        print('All the  results were written in {}'.format(savefolder))\n",
    "\n",
    "    return contrasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over each subject to load files and create GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_glm_model(subjID,run_list,savename,savetype='t-stat',plot=False):\n",
    "    print('Working on GLM for {}\\n...'.format(savename))\n",
    "    fmri_img=get_image_list(subjID,run_list)\n",
    "    dm_list=get_design_matrices(subjID,run_list,plot=plot)\n",
    "    fmri_glm=generate_glm(fmri_img,dm_list,maskfile)\n",
    "\n",
    "    contrasts=compute_contrasts2(subjID,dm_list,['transition'],fmri_glm,\n",
    "                                 savename,savetype=savetype,plot=plot)\n",
    "\n",
    "    #Save GLM parameters into npz file\n",
    "    savefile=opj(path_l1Data,savename,'{}_{}_l1_inputs.npz'.format(subjID,savename))\n",
    "    np.savez(savefile,{'design_matrices':dm_list,'glm_parameters':fmri_glm,'contrasts':contrasts})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs_to_process=[s for s in subjs if len(glob.glob('{}/{}/func/swcad*'.format(path_InpData,s)))==10]\n",
    "print('{} subjects to process'.format(len(subjs_to_process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix,subj in enumerate(subjs_to_process):\n",
    "    print('*'*30,subj,'(',(ix+1),'of',len(subjs_to_process),')','*'*30)\n",
    "    savename='task1'\n",
    "    final_file='{}_{}_l1_inputs.npz'.format(subj,savename)\n",
    "    loop_glm_model(subjID=subj, run_list=task1, savename=savename, savetype='z_score',plot=False)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix,subj in enumerate(subjs_to_process):\n",
    "    print('*'*30,subj,'(',(ix+1),'of',len(subjs_to_process),')','*'*30)\n",
    "    savename='task2'\n",
    "    final_file='{}_{}_l1_inputs.npz'.format(subj,savename)\n",
    "    loop_glm_model(subjID=subj, run_list=task2, savename=savename, savetype='z_score',plot=False)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step 3: Second level analysis\n",
    "\n",
    "Analysis Steps:\n",
    "\n",
    "1. Create design matrix\n",
    "2. Specify GLM\n",
    "3. Run contrasts\n",
    "4. Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a simple experimental paradigm\n",
    "\n",
    "We want to get the group result of a contrast for 26 subjects who completed both the social and non-social tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_links.loc[:,'nsFile']='NA'\n",
    "subj_links.loc[:,'socFile']='NA'\n",
    "for subj in subj_links['pID']:\n",
    "    cond=subj_links.loc[subj_links['pID']==subj,'CondNum'].tolist()[0]\n",
    "    scanID=subj_links.loc[subj_links['pID']==subj,'scanID'].tolist()[0]\n",
    "    if cond==1:\n",
    "        nsFile='{}_task1_Transition_z_map.nii.gz'.format(scanID)\n",
    "        socFile='{}_task2_Transition_z_map.nii.gz'.format(scanID)\n",
    "    else:\n",
    "        nsFile='{}_task2_Transition_z_map.nii.gz'.format(scanID)\n",
    "        socFile='{}_task1_Transition_z_map.nii.gz'.format(scanID)\n",
    "    subj_links.loc[subj_links['pID']==subj,'nsFile']=nsFile\n",
    "    subj_links.loc[subj_links['pID']==subj,'socFile']=socFile\n",
    "\n",
    "subj_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of files for social and non-social tasks\n",
    "mapfiles_ns=[opj(path_l1Data,x) for x in subj_links.loc[:,'nsFile']]\n",
    "mapfiles_soc=[opj(path_l1Data,x) for x in subj_links.loc[:,'socFile']]\n",
    "mapfiles=mapfiles_ns+mapfiles_soc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify extra information about the subjects to add confounds to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subjs = len(subj_links)\n",
    "subjects_label = [x[:13] for x in subj_links['nsFile']]+[x[:13] for x in subj_links['socFile']]\n",
    "subject_ids = [x for x in subj_links['rowID']]*2\n",
    "order_labels = np.array([x-1 for x in subj_links['CondNum']]*2) #order=-1: ns first; order=1; soc first\n",
    "order_labels[order_labels==0]=-1\n",
    "cond_labels = [-1]*n_subjs + [1]*n_subjs #cond=-1: ns; cond=1: soc\n",
    "\n",
    "#Add variables for subject ID, condition number, and order\n",
    "extra_info_subjects = pd.DataFrame({'subj':subject_ids,\n",
    "                                    'cond': cond_labels,\n",
    "                                    'order': order_labels})\n",
    "\n",
    "# Make sure variables are mean-centered\n",
    "extra_info_subjects = extra_info_subjects.subtract(extra_info_subjects.mean())\n",
    "\n",
    "# Add in character label for each subject\n",
    "extra_info_subjects['subject_label']= subjects_label\n",
    "\n",
    "extra_info_subjects.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot glass brain images of first-level results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = subj_links.loc[:,'scanID'].tolist()\n",
    "fig, axes = plt.subplots(nrows=7, ncols=4,figsize=(15, 15))\n",
    "for cidx, tfile in enumerate(subj_links.loc[:,'nsFile']):\n",
    "    tmap=opj(path_l1Data,tfile)\n",
    "    plotting.plot_glass_brain(tmap, colorbar=False, threshold=2.5,\n",
    "                              title=subjects[cidx],\n",
    "                              axes=axes[int(cidx / 4), int(cidx % 4)],\n",
    "                              plot_abs=False, display_mode='z')\n",
    "fig.suptitle('Subjects Z-map Non-Social Task')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "subjects = subj_links.loc[:,'scanID'].tolist()\n",
    "fig, axes = plt.subplots(nrows=7, ncols=4,figsize=(15, 15))\n",
    "for cidx, tfile in enumerate(subj_links.loc[:,'socFile']):\n",
    "    tmap=opj(path_l1Data,tfile)\n",
    "    plotting.plot_glass_brain(tmap, colorbar=False, threshold=2.5,\n",
    "                              title=subjects[cidx],\n",
    "                              axes=axes[int(cidx / 4), int(cidx % 4)],\n",
    "                              plot_abs=False, display_mode='z')\n",
    "fig.suptitle('Subjects Z-map Social Task')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create second-level design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix = make_second_level_design_matrix(subjects_label, extra_info_subjects)\n",
    "design_matrix_ns = design_matrix.loc[design_matrix['cond']==0,['order','intercept']]\n",
    "design_matrix_soc = design_matrix.loc[design_matrix['cond']==1,['order','intercept']]\n",
    "\n",
    "# plot the results\n",
    "ax = plot_design_matrix(design_matrix)\n",
    "ax.set_title('Second level design matrix', fontsize=12)\n",
    "ax.set_ylabel('maps')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify GLM and visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level_input = mapfiles\n",
    "\n",
    "second_level_model = SecondLevelModel(smoothing_fwhm=None)\n",
    "second_level_model = second_level_model.fit(second_level_input,design_matrix=design_matrix)\n",
    "print(second_level_model)\n",
    "for x in ['cond','intercept']:\n",
    "    z_map = second_level_model.compute_contrast(second_level_contrast=x,second_level_stat_type='t',output_type='z_score')\n",
    "    z_file = '{}/netLearn_{}Xtransition_secondLevel_zmap.nii.gz'.format(path_l2Data,x)\n",
    "    nb.save(z_map,z_file)\n",
    "    \n",
    "    p_val = 0.001\n",
    "    z_th = norm.isf(p_val)\n",
    "    display=plotting.plot_stat_map(z_map,threshold=z_th,colorbar=True,\n",
    "                                   display_mode='x',cut_coords=[-55,-25,-5,5,25,55],\n",
    "                      title='{} x transition contrast (unc p<0.001)'.format(x))\n",
    "    plotting.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
