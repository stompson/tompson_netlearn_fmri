{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute z-scores using PPI matrices and null models\n",
    "This script takes the PPI matrices for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "import scipy.stats as ss\n",
    "import os\n",
    "from os.path import join as opj\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nilearn import image, plotting\n",
    "import nibabel as nb\n",
    "import bct\n",
    "from mne.stats import fdr_correction\n",
    "from nistats import thresholding\n",
    "from random import shuffle\n",
    "\n",
    "print('Done Importing Packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to directory where you saved the data\n",
    "home_path = '/Users/steventompson/Git/tompson_netlearn_fmri'\n",
    "\n",
    "data_dir = opj(home_path,'data')\n",
    "template_dir = opj(data_dir,'brain_atlas')\n",
    "path_InpData = opj(data_dir,'netLearn_ppi')\n",
    "path_NullData = opj(data_dir,'netLearn_ppi_null')\n",
    "path_OutpData = opj(data_dir,'ppi_zscores')\n",
    "path_Figures = opj(home_path,'figures','component_figs') # folder to put figures\n",
    "\n",
    "\n",
    "for path in [path_OutpData, path_Figures]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path does not exist, creating {}'.format(path))\n",
    "        os.makedirs(path)\n",
    "\n",
    "print('Set data paths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "n_subjs = 26\n",
    "n_node = 410\n",
    "n_perm = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_cfg_vec_to_adj_matr(conn_vec):\n",
    "    '''\n",
    "    Convert connections to adjacency matrix\n",
    "    Assumes symmetric connectivity\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        conn_vec: numpy.ndarray\n",
    "            Vector with shape (n_conn,) specifying unique connections\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        adj_matr: numpy.ndarray\n",
    "            Symmetric matrix with shape (n_node, n_node)\n",
    "    '''\n",
    "    # Standard param checks\n",
    "    #errors.check_type(conn_vec, np.ndarray)\n",
    "    if not len(conn_vec.shape) == 1:\n",
    "        raise ValueError('%r has more than 1-dimension')\n",
    "\n",
    "    # Compute number of nodes\n",
    "    n_node = int(np.floor(np.sqrt(2*len(conn_vec)))+1)\n",
    "\n",
    "    # Compute upper triangle indices (by convention)\n",
    "    triu_ix, triu_iy = np.triu_indices(n_node, k=1)\n",
    "\n",
    "    # Convert to adjacency matrix\n",
    "    adj_matr = np.zeros((n_node, n_node))\n",
    "    adj_matr[triu_ix, triu_iy] = conn_vec\n",
    "\n",
    "    adj_matr += adj_matr.T\n",
    "\n",
    "    return adj_matr\n",
    "\n",
    "\n",
    "def convert_adj_matr_to_cfg_matr(adj_matr):\n",
    "    '''\n",
    "    Convert connections to adjacency matrix\n",
    "    Assumes symmetric connectivity\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        adj_matr: numpy.ndarray\n",
    "            Matrix with shape (n_win, n_node, n_node)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        cfg_matr: numpy.ndarray\n",
    "            Symmetric matrix with shape (n_win, n_conn)\n",
    "    '''\n",
    "    # Standard param checks\n",
    "    #errors.check_type(adj_matr, np.ndarray)\n",
    "    if not len(adj_matr.shape) == 3:\n",
    "        raise ValueError('%r requires 3-dimensions (n_win, n_node, n_node)')\n",
    "\n",
    "    # Compute number of nodes\n",
    "    n_node = adj_matr.shape[1]\n",
    "\n",
    "    # Compute upper triangle indices (by convention)\n",
    "    triu_ix, triu_iy = np.triu_indices(n_node, k=1)\n",
    "\n",
    "    # Convert to configuration matrix\n",
    "    cfg_matr = adj_matr[:, triu_ix, triu_iy]\n",
    "\n",
    "    return cfg_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pval_twotail(test_val,null_dist,plot=False,plot_title=''):\n",
    "    '''\n",
    "    Compute the p-value and z-score for a test value given a null distribution\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        test_val: float\n",
    "            numeric value to compare to null distribution\n",
    "        null_dist: numpy array\n",
    "            1D array of numeric values to compare with test_val\n",
    "        plot: boolean\n",
    "            boolean indicating whether to plot the distribution\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        zval: float\n",
    "            z-score of the test_val\n",
    "        pval: float\n",
    "            p-value of the test_val\n",
    "    '''\n",
    "    pval=ss.percentileofscore(null_dist,test_val)/100\n",
    "    zval=ss.norm.ppf(pval)\n",
    "    if pval>0.5:\n",
    "        pval=(1-pval)\n",
    "    # Set zvals where p=0.00000 to an arbitrary value \n",
    "    #in this case p=.0005 and z=3.29 or -3.29, \n",
    "    #which should be greater than max value so long as len(null_dist)<2000\n",
    "    if zval==-inf:\n",
    "        zval=ss.norm.ppf(.0005)\n",
    "    elif zval==inf:\n",
    "        zval=ss.norm.ppf(.9995)\n",
    "    if plot:\n",
    "        plt.hist(np.append(test_val,null_dist),bins=50)\n",
    "        plt.axvline(x=test_val,color='black')\n",
    "        plt.text(x=np.max(null_dist)*.9,y=10,s='P-val={}'.format(pval))\n",
    "        plt.title(plot_title)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    return zval,pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_zData=opj(home_path1,'data','netLearn_ppi_zscores')\n",
    "filelist=[f for f in os.listdir(path_zData) if f.endswith('.csv')]\n",
    "for filename in filelist:\n",
    "    data=pd.read_csv(opj(path_zData,filename))\n",
    "    data=data.replace(-4,ss.norm.ppf(0.0005))\n",
    "    data=data.replace(4,ss.norm.ppf(0.9995))\n",
    "    data=data.drop('Unnamed: 0',axis=1)\n",
    "    data.to_csv(opj(path_zData,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load schaefer mask\n",
    "schaefer_mask=nb.load('{}/schaefer400_harvard_oxford_2mm_mni_17network.nii.gz'.format(template_dir))\n",
    "\n",
    "#load schaefer atlas info\n",
    "#schaefer_atlas=pd.read_pickle('{}/s400ho_ns_netLearn_2mm.pickle'.format(template_dir))\n",
    "schaefer_atlas=pd.read_csv('{}/s400ho_netLearn_2mm.csv'.format(template_dir))\n",
    "schaefer_atlas_new=pd.read_pickle('{}/s400ho_ns_netLearn_2mm_new.pickle'.format(template_dir))\n",
    "\n",
    "schaefer_atlas=schaefer_atlas.fillna('Uncertain')\n",
    "schaefer_atlas.loc[schaefer_atlas['System']=='Uncertain','System']='Subcortical'\n",
    "\n",
    "schaefer_atlas.loc[[402,407],'System']='Hippocampus'\n",
    "schaefer_atlas.loc[[402,407],'System7']='Hippocampus'\n",
    "\n",
    "sch_names=np.unique(schaefer_atlas['System'])\n",
    "sch_nums=[int(np.where(sch_names==label)[0]) for label in schaefer_atlas['System']]\n",
    "\n",
    "\n",
    "schaefer_atlas.loc[schaefer_atlas['System7']=='Uncertain','System7']='Subcortical'\n",
    "sch7_names=np.unique(schaefer_atlas['System7'])\n",
    "sch7_nums=[int(np.where(sch7_names==label)[0]) for label in schaefer_atlas['System7']]\n",
    "\n",
    "net_coords=np.array(schaefer_atlas.loc[:,['x','y','z']])\n",
    "net_cols=['black']*len(net_coords)\n",
    "\n",
    "n_node = len(sch_nums)\n",
    "triu_ix, triu_iy = np.triu_indices(n_node, k=1)\n",
    "n_conn = len(triu_ix)\n",
    "\n",
    "n_perm = 500\n",
    "\n",
    "schaefer_atlas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schaefer_atlas_new.loc[schaefer_atlas['ns_ROI_label']!=schaefer_atlas_new['ns_ROI_label'],['nID','Name','ROI_label','ns_ROI_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schaefer_atlas.loc[schaefer_atlas['ns_ROI_label']!=schaefer_atlas_new['ns_ROI_label'],['nID','Name','ROI_label','ns_ROI_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in [363,364,371]:\n",
    "    print(ix,'Old: {}'.format(schaefer_atlas.loc[ix,'ns_ROI_label']),\n",
    "          ' New: {}'.format(schaefer_atlas_new.loc[ix,'ns_ROI_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schaefer_atlas.loc[:,['nID','Name','System7','Peak AAL Label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffhubs_ns_new=[165, 177, 182, 304, 308, 310, 332, 364, 370, 376, 378]\n",
    "diffhubs_ns_old=[165, 177, 182, 304, 308, 310, 332, 370, 371, 376, 378]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schaefer_atlas=schaefer_atlas.drop(['ID', u'Name', 'netNum','Label', 'lNum', 'col1', 'col2', 'col3','col4',\n",
    "                     'Peak AAL Label','Mode AAL Label',\n",
    "                     'mentalizing','memory','workMem','reward',\n",
    "                     'tpj','mpfc','ifg','vlpfc','dlpfc', 'pcc', 'hippocampus', 'striatum', \n",
    "                     'MentvWM', 'MentvMem','ment_bi','workMem_bi','mem_bi'],axis=1)\n",
    "schaefer_atlas.to_csv(opj(template_dir,'s400ho_netLearn_2mm.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Compute edge-wise z-scores for connectivity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subject data\n",
    "diffData=np.load(opj(path_InpData,'netLearn_diff_transition_PPI_26subjs.npz'))\n",
    "combData=np.load(opj(path_InpData,'netLearn_comb_transition_PPI_26subjs.npz'))\n",
    "\n",
    "diffMat1=np.expand_dims(np.mean(diffData['ppiMat'],axis=0),axis=0)\n",
    "combMat1=np.expand_dims(np.mean(combData['ppiMat'],axis=0),axis=0)\n",
    "\n",
    "# Load null data\n",
    "comb_nullMat=np.load(opj(path_NullData,'netLearn_comb_nulldata_transition_PPI_26subjs_groupavg.npz'))['cfgMat']\n",
    "diff_nullMat=np.load(opj(path_NullData,'netLearn_diff_nulldata_transition_PPI_26subjs_groupavg.npz'))['cfgMat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_zscores(roi_cfg,null_cfg,thresh=False,savename='test'):\n",
    "    print('')\n",
    "    roi_cfg=roi_cfg.squeeze()\n",
    "    null_cfg=null_cfg.squeeze()\n",
    "    nconn=roi_cfg.shape[-1]\n",
    "    zmat=np.zeros(roi_cfg.shape)\n",
    "    pmat=zmat.copy()\n",
    "    for x in range(nconn):\n",
    "        if x==0:\n",
    "            print('Working on edge 1',end='')\n",
    "        elif (x+1)%(int(nconn/10))==0:\n",
    "            print('...{}'.format(x+1),end='')\n",
    "        elif (x+1)==nconn:\n",
    "            print('')\n",
    "        zval,pval=compute_pval_twotail(roi_cfg[x],null_cfg[:,x])\n",
    "        zmat[x]=zval\n",
    "        pmat[x]=pval\n",
    "        \n",
    "    print('...')\n",
    "    print('Computed zMat and pMat for {} edges'.format(len(pmat)))\n",
    "    if thresh:\n",
    "        reject_fdr,fdr_pvals=fdr_correction(pmat)\n",
    "        n_sig=np.sum(reject_fdr)\n",
    "        print('# of significant edge: {}'.format(n_sig))\n",
    "        zmat=np.multiply(zmat,reject_fdr)\n",
    "        pmat=fdr_pvals\n",
    "    savefile='{}/{}'.format(path_OutpData,savename)\n",
    "    np.savez(savefile,zMat=zmat,pMat=pmat)\n",
    "    print('Saving file to {}.npz'.format(savefile))\n",
    "    print('...')\n",
    "    #return zMat,pMat\n",
    "\n",
    "get_edge_zscores(roi_cfg=diffMat1,null_cfg=diff_nullMat,savename='netLearn_diffData_zscores_groupavg_410nodes_connmat')\n",
    "get_edge_zscores(roi_cfg=combMat1,null_cfg=comb_nullMat,savename='netLearn_combData_zscores_groupavg_410nodes_connmat')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Compute node-strength z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conlist=['diff','comb','soc','nonSoc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adj_mat is 3-d matrix with n_subj x n_conn shape\n",
    "#colID is a string indicating the node to get connectivity with\n",
    "#colindex is a list of strings indicating the names of each row/column in adj_mat\n",
    "def get_nodestr_means(cfg_mat):\n",
    "    adj_mat=conv_cfg_vec_to_adj_matr(cfg_mat)\n",
    "    rowMeans=np.mean(adj_mat,axis=-1)\n",
    "    return rowMeans\n",
    "\n",
    "def get_null_nodestr_means(cfg_mat):\n",
    "    adj_mat=np.zeros((n_perm,n_node,n_node))\n",
    "    for xx in range(n_perm):\n",
    "        adj_mat[xx,:,:]=conv_cfg_vec_to_adj_matr(cfg_mat[xx,:])\n",
    "    rowMeans=np.mean(adj_mat,axis=-1)\n",
    "    return rowMeans\n",
    "\n",
    "\n",
    "def get_nodestr_zscores(task,thresh=False,savename='test'):\n",
    "    # Load subject data\n",
    "    cfg_data=np.load(opj(path_InpData,'netLearn_{}_transition_PPI_26subjs.npz'.format(task)))\n",
    "    \n",
    "    # Compute subject average\n",
    "    roi_cfg=np.mean(cfg_data['ppiMat'],axis=0)\n",
    "    \n",
    "    # Load null data (already averaged across subjects)\n",
    "    null_cfg=np.load(opj(path_NullData,'netLearn_{}_nulldata_transition_PPI_26subjs_groupavg.npz'.format(task)))['cfgMat']\n",
    "    print('')\n",
    "    print('Getting node strength vals')\n",
    "    node_vec=get_nodestr_means(roi_cfg)\n",
    "    print('Getting nullmat node strength vals')\n",
    "    null_mat=get_null_nodestr_means(null_cfg)\n",
    "    zMat=np.zeros(node_vec.shape)\n",
    "    pMat=zMat.copy()\n",
    "    for x in range(n_node):\n",
    "        if x==0:\n",
    "            print('Working on node 1',end='')\n",
    "        elif (x+1)%(int(n_node/10))==0:\n",
    "            print('...{}'.format(x+1),end='')\n",
    "        elif (x+1)==n_node:\n",
    "            print('')\n",
    "        zval,pval=compute_pval_twotail(node_vec[x],null_mat[:,x])\n",
    "        zMat[x]=zval\n",
    "        pMat[x]=pval\n",
    "    print('...')\n",
    "    print('Computed zMat and pMat for {} nodes'.format(len(pMat)))\n",
    "    #np.array([(ss.percentileofscore(null_mat[:,x],roi_mat[x])/100) for x in range(n_node)])\n",
    "    if thresh:\n",
    "        reject_fdr,fdr_pvals=fdr_correction(pMat)\n",
    "        n_sig=np.sum(reject_fdr)\n",
    "        print('# of significant nodes is: {}'.format(n_sig))\n",
    "        zMat=np.multiply(zMat,reject_fdr)\n",
    "        pMat=fdr_pvals\n",
    "    \n",
    "    savefile='{}/{}'.format(path_OutpData,savename)\n",
    "    np.savez(savefile,zMat=zMat,pMat=pMat)\n",
    "    print('Saving file to {}.npz'.format(savefile))\n",
    "    print('...')\n",
    "    #return zMat,pMat\n",
    "\n",
    "\n",
    "for task in conlist:\n",
    "    print('Working on contrast {}'.format(task))\n",
    "    get_nodestr_zscores(task,thresh=False,savename='netLearn_{}Data_zscores_26subjs_nodestr'.format(task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Get list of hubs\n",
    "\n",
    "All Tasks- Global Connectivity\n",
    "10 significant positive ROIs in a priori regions\n",
    "\n",
    "Social versus Non-Social- Global Connectivity\n",
    "6 significant positive ROIs in a priori regions\n",
    "\n",
    "Social versus Non-Social- Global Connectivity\n",
    "11 significant positive ROIs in a priori regions\n",
    "\n",
    "Column ids for dmPFC_L= [165, 174]\n",
    "Column ids for vmPFC_L= [160]\n",
    "Column ids for TPJ_R= [244]\n",
    "Column ids for Hippocampus_R= [407]\n",
    "Column ids for combhubs= [44, 160, 165, 174, 244, 370, 376, 378, 402, 407]\n",
    "Column ids for TPJ_L= [44]\n",
    "Column ids for Hippocampus_L= [402]\n",
    "Column ids for Hippocampus= [402, 407]\n",
    "Column ids for dmPFC_R= [370, 376, 378]\n",
    "\n",
    "Column ids for TPJ_R= [262, 394, 396, 397]\n",
    "Column ids for diffhubs= [85, 172, 262, 394, 396, 397]\n",
    "Column ids for TPJ_L= [85, 172]\n",
    "\n",
    "Column ids for lPFC_L= [182]\n",
    "Column ids for dmPFC_L= [165, 177]\n",
    "Column ids for Frontal_Inf_Orb_R= [308]\n",
    "Column ids for diffhubs_ns= [165, 177, 182, 304, 308, 310, 332, 370, 371, 376, 378]\n",
    "Column ids for Frontal_Inf_Oper_R= [332]\n",
    "Column ids for Frontal_Inf_Orb_L= [182]\n",
    "Column ids for dmPFC_R= [310, 370, 371, 376, 378]\n",
    "Column ids for lPFC_R= [308, 332, 304]\n",
    "Column ids for Frontal_Inf_Tri_R= [304]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list1=['combData','diffData','nonSocData','SocData']\n",
    "list1_labels=['All Tasks','Social versus Non-Social','Non-Social Task','Social Task']\n",
    "list2=['nodestr']\n",
    "list2_labels=['Global']\n",
    "\n",
    "\n",
    "apriori_names=['dmPFC_L','vmPFC_L','PCC_L','Hippocampus_L','TPJ_L',\n",
    "               'dmPFC_R','vmPFC_R','PCC_R','Hippocampus_R','TPJ_R',\n",
    "               'Frontal_Inf_Oper_L','Frontal_Inf_Orb_L','Frontal_Inf_Tri_L',\n",
    "               'Frontal_Inf_Oper_R','Frontal_Inf_Orb_R','Frontal_Inf_Tri_R',\n",
    "               'Amygdala_L','Amygdala_R',\n",
    "               'Ventral_Striatum_L','Caudate_L',\n",
    "               'Ventral_Striatum_R','Caudate_R']\n",
    "\n",
    "\n",
    "\n",
    "def identify_hubs1(ix,iy,thresh=True,apriori=True,flip=False,alpha=0.05):\n",
    "    xx=list2[ix]\n",
    "    yy=list1[iy]\n",
    "    data=np.load('{}/netLearn_{}_zscores_26subjs_{}.npz'.format(path_zData,yy,xx))\n",
    "    zMat=data['zMat']\n",
    "    pMat=data['pMat']\n",
    "    #pMat=np.multiply(data['pMat'],2)\n",
    "    \n",
    "    if flip:\n",
    "        zMat=np.multiply(zMat,-1)\n",
    "    \n",
    "    # Set nonsignificant values to zero using FDR correction\n",
    "    if thresh:\n",
    "        reject_fdr,pval_fdr=fdr_correction(pMat,alpha)\n",
    "        zMat=np.multiply(zMat,reject_fdr)\n",
    "\n",
    "    title='{}- {} Connectivity'.format(list1_labels[iy],list2_labels[ix])\n",
    "    sig_ix=np.where(zMat>0)[0]\n",
    "    sig_dic={}\n",
    "    sig_vec=np.zeros(zMat.shape)\n",
    "    if apriori:\n",
    "        sig_ix=[x for x in sig_ix if schaefer_atlas.loc[x,'ns_ROI_label'] in apriori_names]\n",
    "        for i,x in enumerate(apriori_names):\n",
    "            sig_dic[x]=[ix for ix in sig_ix if schaefer_atlas.loc[ix,'ns_ROI_label']==x]\n",
    "            sig_dic=dict((k, v) for k, v in sig_dic.iteritems() if v)\n",
    "\n",
    "    sig_vec[sig_ix]=1\n",
    "        \n",
    "    print('')\n",
    "    print(title)\n",
    "    print('{} significant positive ROIs in a priori regions'.format(len(sig_ix)))\n",
    "    return sig_ix,sig_vec,sig_dic\n",
    "    \n",
    "sigvals_comb,sigvec_comb,sigdic_comb=identify_hubs1(0,0,alpha=0.025)\n",
    "signames_comb=schaefer_atlas.loc[sigvals_comb,'ns_ROI_label']\n",
    "\n",
    "sigvals_diff,sigvec_diff,sigdic_diff=identify_hubs1(0,1,alpha=0.025)\n",
    "signames_diff=schaefer_atlas.loc[sigvals_diff,'ns_ROI_label']\n",
    "\n",
    "\n",
    "sigvals_diff_ns,sigvec_diff_ns,sigdic_diff_ns=identify_hubs1(0,1,flip=True,alpha=0.025)\n",
    "signames_diff_ns=schaefer_atlas.loc[sigvals_diff_ns,'ns_ROI_label']\n",
    "\n",
    "sigdic_comb['Hippocampus']=[402,407]\n",
    "sigdic_comb['combhubs']=sigvals_comb\n",
    "sigdic_diff['diffhubs']=sigvals_diff\n",
    "sigdic_diff_ns['diffhubs_ns']=sigvals_diff_ns\n",
    "\n",
    "lpfc_l_vals=[sigdic_diff_ns[key] for key in sigdic_diff_ns.keys() if 'Frontal' in key and '_L' in key]\n",
    "sigdic_diff_ns['lPFC_L']=[item for sublist in lpfc_l_vals for item in sublist]\n",
    "lpfc_r_vals=[sigdic_diff_ns[key] for key in sigdic_diff_ns.keys() if 'Frontal' in key and '_R' in key]\n",
    "sigdic_diff_ns['lPFC_R']=[item for sublist in lpfc_r_vals for item in sublist]\n",
    "\n",
    "\n",
    "for x in sigdic_comb.keys():\n",
    "    print('Column ids for {}= {}'.format(x,sigdic_comb[x]))\n",
    "    \n",
    "print('')\n",
    "for x in sigdic_diff.keys():\n",
    "    print('Column ids for {}= {}'.format(x,sigdic_diff[x]))\n",
    "    \n",
    "print('')\n",
    "for x in sigdic_diff_ns.keys():\n",
    "    print('Column ids for {}= {}'.format(x,sigdic_diff_ns[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schaefer_atlas.loc[[363,364,371],['nID','x','y','z','ns_ROI_label','ROI_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list1=['combData','diffData','nonSocData','SocData']\n",
    "list1_labels=['All Tasks','Social versus Non-Social','Non-Social Task','Social Task']\n",
    "list2=['all']\n",
    "list2_labels=['Global']\n",
    "\n",
    "\n",
    "apriori_names=['dmPFC_L','vmPFC_L','PCC_L','Hippocampus_L','TPJ_L',\n",
    "               'dmPFC_R','vmPFC_R','PCC_R','Hippocampus_R','TPJ_R',\n",
    "               'Frontal_Inf_Oper_L','Frontal_Inf_Orb_L','Frontal_Inf_Tri_L',\n",
    "               'Frontal_Inf_Oper_R','Frontal_Inf_Orb_R','Frontal_Inf_Tri_R',\n",
    "               'Amygdala_L','Amygdala_R',\n",
    "               'Ventral_Striatum_L','Caudate_L',\n",
    "               'Ventral_Striatum_R','Caudate_R']\n",
    "\n",
    "\n",
    "\n",
    "def identify_hubs1(ix,iy,thresh=True,apriori=True,flip=False,alpha=0.05):\n",
    "    xx=list2[ix]\n",
    "    yy=list1[iy]\n",
    "    data=np.load('{}/netLearn_{}_zscores_410nodes_{}.npz'.format(path_zData,yy,xx))\n",
    "    zMat=data['zMat']\n",
    "    pMat=data['pMat']\n",
    "    \n",
    "    zMat[zMat=4]\n",
    "    #pMat=np.multiply(data['pMat'],2)\n",
    "    \n",
    "    if flip:\n",
    "        zMat=np.multiply(zMat,-1)\n",
    "    \n",
    "    # Set nonsignificant values to zero using FDR correction\n",
    "    if thresh:\n",
    "        reject_fdr,pval_fdr=fdr_correction(pMat,alpha)\n",
    "        zMat=np.multiply(zMat,reject_fdr)\n",
    "\n",
    "    title='{}- {} Connectivity'.format(list1_labels[iy],list2_labels[ix])\n",
    "    sig_ix=np.where(zMat>0)[0]\n",
    "    sig_dic={}\n",
    "    sig_vec=np.zeros(zMat.shape)\n",
    "    if apriori:\n",
    "        sig_ix=[x for x in sig_ix if schaefer_atlas.loc[x,'ns_ROI_label'] in apriori_names]\n",
    "        for i,x in enumerate(apriori_names):\n",
    "            sig_dic[x]=[ix for ix in sig_ix if schaefer_atlas.loc[ix,'ns_ROI_label']==x]\n",
    "            sig_dic=dict((k, v) for k, v in sig_dic.iteritems() if v)\n",
    "\n",
    "    sig_vec[sig_ix]=1\n",
    "        \n",
    "    print('')\n",
    "    print(title)\n",
    "    print('{} significant positive ROIs in a priori regions'.format(len(sig_ix)))\n",
    "    return sig_ix,sig_vec,sig_dic\n",
    "    \n",
    "sigvals_comb,sigvec_comb,sigdic_comb=identify_hubs1(0,0,alpha=0.025)\n",
    "signames_comb=schaefer_atlas.loc[sigvals_comb,'ns_ROI_label']\n",
    "\n",
    "sigvals_diff,sigvec_diff,sigdic_diff=identify_hubs1(0,1,alpha=0.025)\n",
    "signames_diff=schaefer_atlas.loc[sigvals_diff,'ns_ROI_label']\n",
    "\n",
    "\n",
    "sigvals_diff_ns,sigvec_diff_ns,sigdic_diff_ns=identify_hubs1(0,1,flip=True,alpha=0.025)\n",
    "signames_diff_ns=schaefer_atlas.loc[sigvals_diff_ns,'ns_ROI_label']\n",
    "\n",
    "sigdic_comb['Hippocampus']=[402,407]\n",
    "sigdic_comb['combhubs']=sigvals_comb\n",
    "sigdic_diff['diffhubs']=sigvals_diff\n",
    "sigdic_diff_ns['diffhubs_ns']=sigvals_diff_ns\n",
    "\n",
    "lpfc_l_vals=[sigdic_diff_ns[key] for key in sigdic_diff_ns.keys() if 'Frontal' in key and '_L' in key]\n",
    "sigdic_diff_ns['lPFC_L']=[item for sublist in lpfc_l_vals for item in sublist]\n",
    "lpfc_r_vals=[sigdic_diff_ns[key] for key in sigdic_diff_ns.keys() if 'Frontal' in key and '_R' in key]\n",
    "sigdic_diff_ns['lPFC_R']=[item for sublist in lpfc_r_vals for item in sublist]\n",
    "\n",
    "\n",
    "for x in sigdic_comb.keys():\n",
    "    print('Column ids for {}= {}'.format(x,sigdic_comb[x]))\n",
    "    \n",
    "print('')\n",
    "for x in sigdic_diff.keys():\n",
    "    print('Column ids for {}= {}'.format(x,sigdic_diff[x]))\n",
    "    \n",
    "print('')\n",
    "for x in sigdic_diff_ns.keys():\n",
    "    print('Column ids for {}= {}'.format(x,sigdic_diff_ns[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_names=['dmPFC_L','vmPFC_L','PCC_L','Hippocampus_L','TPJ_L',\n",
    "           'dmPFC_R','vmPFC_R','PCC_R','Hippocampus_R','TPJ_R',\n",
    "           'lPFC_L','Amygdala_L','Ventral_Striatum_L','Caudate_L',\n",
    "           'lPFC_R','Amygdala_R','Ventral_Striatum_R','Caudate_R']\n",
    "    \n",
    "roi_names=sorted(roi_names, key=lambda s: s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_dict_remove1(mydict, somekeys,default=None):\n",
    "    somedict=mydict.copy()\n",
    "    tdict=dict([ (k, somedict.pop(k, default)) for k in somekeys ])\n",
    "    return tdict\n",
    "\n",
    "def sub_dict_remove2(mydict, somekeys,default=None):\n",
    "    somedict=mydict.copy()\n",
    "    tdict=dict([ (k, somedict.pop(k, default)) for k in somekeys ])\n",
    "    return dict((k, v) for k, v in tdict.iteritems() if v)\n",
    "\n",
    "sigdic_rois={'ns_hub':sigdic_diff_ns.copy(),\n",
    "             'soc_hub':sigdic_diff.copy(),\n",
    "             'comb_hub':sigdic_comb.copy()}\n",
    "\n",
    "for key in sigdic_rois:\n",
    "    sigdic_rois[key]=sub_dict_remove2(sigdic_rois[key],roi_names)\n",
    "    \n",
    "syslist_rois={}\n",
    "for k1 in sigdic_rois.keys():\n",
    "    for k2 in sigdic_rois[k1].keys():\n",
    "        syslist_rois['{}_{}'.format(k1,k2)]=sigdic_rois[k1][k2]\n",
    "                \n",
    "print('{} hubs in syslist_rois'.format(len(syslist_rois)))\n",
    "\n",
    "keys1=[key for key in syslist_rois.keys() if 'soc' in key or 'ns' in key or 'Hippocampus_' in key]\n",
    "\n",
    "syslist_rois2=sub_dict_remove2(syslist_rois,keys1)\n",
    "\n",
    "syslist_rois2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: Get z-scored hub connectivity for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "#adj_mat is 3-d matrix with n_subj x n_conn shape\n",
    "#colID is a string indicating the node to get connectivity with\n",
    "#colindex is a list of strings indicating the names of each row/column in adj_mat\n",
    "def get_means(adj_mat,row_ix,col_ix):\n",
    "    #cfg_mat is a 3D n_subjs x n_perm x n_conn np array\n",
    "    #row_ix is a list of the row indices to include in the means to extract\n",
    "    #col_ix is a list of the column indices to include in the means to extract\n",
    "    subdata=adj_mat[:,row_ix,:]\n",
    "    subdata=subdata[:,:,col_ix]\n",
    "    rowMeans=np.mean(subdata,axis=(-1,-2))\n",
    "    return rowMeans\n",
    "\n",
    "def get_null_means(adj_mat,row_ix,col_ix):\n",
    "    #cfg_mat is a 3D n_subjs x n_perm x n_conn np array\n",
    "    #row_ix is a list of the row indices to include in the means to extract\n",
    "    #col_ix is a list of the column indices to include in the means to extract\n",
    "    subdata=adj_mat[:,:,row_ix,:]\n",
    "    subdata=subdata[:,:,:,col_ix]\n",
    "    rowMeans=np.mean(subdata,axis=(-1,-2))\n",
    "    return rowMeans\n",
    "\n",
    "def get_subhub_zscores(ppi_mat,null_mat,row_id,col_id,row_dict=None,col_dict=None):\n",
    "    #roi_cfg is a 2D n_subjs x n_conn np array\n",
    "    #nulll_cfg is a 3D n_subjs x n_perm x n_conn np array\n",
    "    #row_id is a string that matches a key in the row_dict (or is 'all' which will get global connectivity)\n",
    "    #row_dict is a dictionary with keys matching a priori hubs and row indices for each hub\n",
    "    #col_id is a string that matches a key in the col_dict (or is 'all' which will get global connectivity)\n",
    "    #col_dict is a dictionary with keys matching a priori hubs and column indices for each hub\n",
    "    #thresh is a boolean determining whether to set non-significant z-scores to zero\n",
    "    print('')\n",
    "    if row_id=='all':\n",
    "        row_ix=range(410)\n",
    "    else:\n",
    "        row_ix=row_dict[row_id]\n",
    "    \n",
    "    if col_id=='all':\n",
    "        col_ix=range(410)\n",
    "    else:\n",
    "        col_ix=col_dict[col_id]\n",
    "        \n",
    "    print('Getting subject averages for {} x {}'.format(row_id,col_id))\n",
    "    node_vec=get_means(ppi_mat,row_ix,col_ix)\n",
    "    \n",
    "    print('Getting nullmat averages for {} x {}'.format(row_id,col_id))\n",
    "    node_null_mat=get_null_means(null_mat,row_ix,col_ix)\n",
    "    \n",
    "    #Create array of zeros to fill with z-scores and p-values\n",
    "    zMat=np.zeros(node_vec.shape)\n",
    "    pMat=zMat.copy()\n",
    "    for x in range(n_subjs):\n",
    "        zval,pval=compute_pval_twotail(node_vec[x],node_null_mat[x,:])\n",
    "        zMat[x]=zval\n",
    "        pMat[x]=pval\n",
    "\n",
    "    print('...')\n",
    "    print('Computed zMat and pMat for {} subjects'.format(len(pMat)))    \n",
    "    return zMat,pMat\n",
    "\n",
    "def load_mat(filename):\n",
    "    # Load subject data\n",
    "    print('Loading {}'.format(opj(path_InpData,filename)))\n",
    "    np_data=np.load(opj(path_InpData,'netLearn_{}_transition_PPI_26subjs.npz'.format(task)))\n",
    "    print('Loaded cfgmat with shape {}'.format(np_data['ppiMat'].shape))\n",
    "    ppi_mat=np.array([conv_cfg_vec_to_adj_matr(np_data['ppiMat'][x,:]) for x in range(n_subjs)])\n",
    "    print('Converted ppimat to shape {}'.format(ppi_mat.shape))\n",
    "    return ppi_mat\n",
    "    \n",
    "def load_null_mat(null_file):\n",
    "    print('Loading {}'.format(opj(path_NullData,null_file)))\n",
    "    null_cfg=np.load(opj(path_NullData,null_file))['cfgMat']\n",
    "    # Compute number of nodes\n",
    "    d1,d2,d3=null_cfg.shape\n",
    "    print('Loaded cfgmat with shape {} x {} x {}'.format(d1,d2,d3))\n",
    "    \n",
    "    nconn=d3\n",
    "    numnode = int(np.floor(np.sqrt(2*(nconn)))+1)\n",
    "    null_mat = np.zeros((d1,d2,numnode, numnode))\n",
    "\n",
    "    for dd1 in range(d1):\n",
    "        for dd2 in range(d2):\n",
    "            null_mat[dd1,dd2,:,:]=conv_cfg_vec_to_adj_matr(null_cfg[dd1,dd2,:])\n",
    "\n",
    "    print('Converted nullmat to shape {}'.format(null_mat.shape))\n",
    "    return null_mat\n",
    "\n",
    "def mult_subj_zscores1(task):\n",
    "    #roi_cfg is a 2D n_subjs x n_conn np array\n",
    "    #nulll_cfg is a 3D n_subjs x n_perm x n_conn np array\n",
    "    #savename is a string to add to csv file being saved\n",
    "    df=pd.DataFrame()\n",
    "    \n",
    "    # load connectivity matrices\n",
    "    print('')\n",
    "    ppi_mat=load_mat('netLearn_{}_transition_PPI_26subjs.npz'.format(task))\n",
    "    print('')\n",
    "    null_mat=load_null_mat('netLearn_{}_nulldata_transition_PPI_26subjs.npz'.format(task))\n",
    "    \n",
    "    for a in ['combhubs','Hippocampus','Hippocampus_L','Hippocampus_R']:\n",
    "    #for a in ['Hippocampus','Hippocampus_L','Hippocampus_R','Frontal_Inf_Orb_L','Frontal_Inf_Tri_R','dmPFC_L','dmPFC_R','vmPFC_L']:\n",
    "            colname='{}_global'.format(a)\n",
    "            sub_z,sub_p=get_subhub_zscores(ppi_mat,null_mat,a,'all',sigdic_comb,sigdic_comb)\n",
    "            df[colname]=sub_z\n",
    "            print('')\n",
    "\n",
    "    #for a in ['PCC_L','TPJ_L','TPJ_R']:\n",
    "    for a in ['diffhubs','TPJ_L','TPJ_R']:\n",
    "            colname='{}_global'.format(a)\n",
    "            sub_z,sub_p=get_subhub_zscores(ppi_mat,null_mat,a,'all',sigdic_diff,sigdic_diff)\n",
    "            df[colname]=sub_z\n",
    "            print('')\n",
    "            \n",
    "    #for a in ['PCC_L','TPJ_L','TPJ_R']:\n",
    "    for a in ['diffhubs_ns','dmPFC_L','dmPFC_R','lPFC_L','lPFC_R']:\n",
    "            colname='{}_global'.format(a)\n",
    "            sub_z,sub_p=get_subhub_zscores(ppi_mat,null_mat,a,'all',sigdic_diff_ns,sigdic_diff_ns)\n",
    "            df[colname]=sub_z\n",
    "            print('')\n",
    "    \n",
    "    df.to_csv('{}/netLearn_{}Data_zscores_26subjs_sighubs_nodestr.csv'.format(path_OutpData,task))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_null=load_null_mat('netLearn_soc_nulldata_transition_PPI_26subjs.npz')\n",
    "test=load_mat('netLearn_soc_transition_PPI_26subjs.npz')\n",
    "\n",
    "zmeans=get_subhub_zscores(test,test_null,'Hippocampus_L','all',sigdic_comb,sigdic_comb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl=np.mean(test[:,402,:],axis=(-1,-2))\n",
    "hl_null=np.mean(test_null[:,:,402,:],axis=(-1,-2))\n",
    "hl1=get_means(adj_mat=test,col_ix=range(410),row_ix=[402])\n",
    "hl1_null=get_null_means(adj_mat=test_null,col_ix=range(410),row_ix=[402])\n",
    "\n",
    "for n in range(n_subjs):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl=test[:,[402],:]\n",
    "hl=hl[:,:,range(410)]\n",
    "hl2=np.mean(hl,axis=(-1,-2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_df=mult_subj_zscores1('soc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_subj_zscores2(task):\n",
    "    #roi_cfg is a 2D n_subjs x n_conn np array\n",
    "    #nulll_cfg is a 3D n_subjs x n_perm x n_conn np array\n",
    "    #savename is a string to add to csv file being saved\n",
    "    df=pd.DataFrame()\n",
    "            \n",
    "    for x in ['Hippocampus','Hippocampus_L','Hippocampus_R']:\n",
    "        for y in ['dmPFC_L','dmPFC_R','lPFC_L','lPFC_R']:\n",
    "        #for y in ['Frontal_Inf_Orb_L','Frontal_Inf_Tri_R','dmPFC_L','dmPFC_R','vmPFC_L']:\n",
    "        #for y in ['all','Frontal_Inf_Orb_L']:\n",
    "            colname='{}_X_{}'.format(x,y)\n",
    "            sub_z,sub_p=get_subhub_zscores(ppi_mat,null_mat,x,y,sigdic_comb,sigdic_diff_ns)\n",
    "            df[colname]=sub_z\n",
    "            print('')\n",
    "\n",
    "        #for y in ['PCC_L','TPJ_L','TPJ_R']:\n",
    "        for y in ['TPJ_L','TPJ_R']:\n",
    "            colname='{}_X_{}'.format(x,y)\n",
    "            sub_z,sub_p=get_subhub_zscores(ppi_mat,null_mat,x,y,sigdic_comb,sigdic_diff)\n",
    "            df[colname]=sub_z\n",
    "            print('')\n",
    "\n",
    "    for x in ['TPJ_L','TPJ_R']:\n",
    "        for y in ['dmPFC_L','dmPFC_R','lPFC_L','lPFC_R']:\n",
    "        #for y in ['Frontal_Inf_Orb_L','Frontal_Inf_Tri_R','dmPFC_L','dmPFC_R','vmPFC_L']:\n",
    "            colname='{}_X_{}'.format(x,y)\n",
    "            sub_z,sub_p=get_subhub_zscores(ppi_mat,null_mat,x,y,sigdic_diff,sigdic_diff_ns)\n",
    "            df[colname]=sub_z\n",
    "            print('')\n",
    "\n",
    "        for y in ['TPJ_L','TPJ_R']:\n",
    "            if x!=y:\n",
    "                colname='{}_X_{}'.format(x,y)\n",
    "                sub_z,sub_p=get_subhub_zscores(ppi_mat,null_mat,x,y,sigdic_diff,sigdic_diff)\n",
    "                df[colname]=sub_z\n",
    "                print('')\n",
    "    \n",
    "    df.to_csv('{}/netLearn_{}Data_zscores_26subjs_sighubs_to_sighubs.csv'.format(path_OutpData,task))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullmeans=get_null_means(test_null,range(10),range(10))\n",
    "nullmeans.shape\n",
    "tmeans=get_means(test,range(10),range(10))\n",
    "tmeans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_df=mult_subj_zscores1(SocData,null_SocData,'SocData')\n",
    "ns_df=mult_subj_zscores1(NSData,null_NSData,'NSData')\n",
    "\n",
    "comb_df=mult_subj_zscores1(combData,null_combData,'combData')\n",
    "diff_df=mult_subj_zscores1(diffData,null_diffData,'diffData')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "comb_df=mult_subj_zscores2(combData,null_combData,'combData')\n",
    "diff_df=mult_subj_zscores2(diffData,null_diffData,'diffData')\n",
    "\n",
    "ns_df=mult_subj_zscores2(NSData,null_NSData,'NSData')\n",
    "soc_df=mult_subj_zscores2(SocData,null_SocData,'SocData')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: Compute system z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_means2(cfg_mat,row_ix,col_ix):\n",
    "    '''\n",
    "    Computes the mean connectivity for each subject for a given set of nodes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        cfg_mat: numpy array\n",
    "            2D n_subjs x n_conn np array OR\n",
    "            3D n_subjs x n_node x n_node np array\n",
    "        row_ix: list\n",
    "            row indices to include in the means to extract\n",
    "        col_ix: list\n",
    "            col indices to include in the means to extract\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        rowMeans: numpy array\n",
    "            1D n_subjs np array\n",
    "    '''\n",
    "    if len(cfg_mat.shape)==3:\n",
    "        adj_mat=cfg_mat.copy()\n",
    "    else:\n",
    "        adj_mat=np.array([conv_cfg_vec_to_adj_matr(cfg_mat[x,:]) for x in range(cfg_mat.shape[0])])\n",
    "    #adj_mat=np.array([conv_cfg_vec_to_adj_matr(cfg_mat[x,:]) for x in range(cfg_mat.shape[0])])\n",
    "    subdata=adj_mat[:,row_ix,:]\n",
    "    subdata=subdata[:,:,col_ix]\n",
    "    rowMeans=np.mean(subdata,axis=(-1,-2)) #note: how to handle rows that contain the diagonal value?\n",
    "    return rowMeans\n",
    "\n",
    "def get_null_means2(cfg_mat,row_ix,col_ix):\n",
    "    '''\n",
    "    Computes the mean connectivity for each subject and each null model for a given set of nodes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        cfg_mat: numpy array\n",
    "            3D n_subjs x n_perm x n_conn np array\n",
    "        row_ix: list\n",
    "            row indices to include in the means to extract\n",
    "        col_ix: list\n",
    "            col indices to include in the means to extract\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        rowMeans: numpy array\n",
    "            2D n_perm x n_subjs np array\n",
    "    '''\n",
    "    n_subjs=cfg_mat.shape[0]\n",
    "    n_perm=cfg_mat.shape[1]\n",
    "    n_node=conv_cfg_vec_to_adj_matr(cfg_mat[0,0,:]).shape[0]\n",
    "\n",
    "    adj_mat=np.zeros((n_subjs,n_perm,n_node,n_node))\n",
    "    for xx in range(n_subjs):\n",
    "        for yy in range(n_perm):\n",
    "            adj_mat[xx,yy,:,:]=conv_cfg_vec_to_adj_matr(cfg_mat[xx,yy,:])\n",
    "    subdata=adj_mat[:,:,row_ix,:]\n",
    "    subdata=subdata[:,:,:,col_ix]\n",
    "    rowMeans=np.mean(subdata,axis=(-1,-2))\n",
    "    return rowMeans\n",
    "\n",
    "def get_sys_zscores(conn_mat,null_mat,node_df,sys_names,colindex,\n",
    "                    plot=None,print_vals=False,thresh=True,alpha=0.025):\n",
    "    sys_df=pd.DataFrame(np.zeros((len(sys_names),len(sys_names))))\n",
    "    sys_df.index=sys_names\n",
    "    sys_df.columns=sys_names\n",
    "    sys_df_zvals=sys_df.copy()\n",
    "    sys_df_pvals=sys_df.copy()\n",
    "        \n",
    "    for sys1 in sys_names:\n",
    "        for sys2 in sys_names:\n",
    "            sys_ix=[i for i,x in enumerate(node_df[colindex]) if sys1==x]\n",
    "            sys_iy=[j for j,y in enumerate(node_df[colindex]) if sys2==y]\n",
    "            #print('{}: {}'.format(sys1,sys_ix))\n",
    "            #print('{}: {}'.format(sys2,sys_iy))\n",
    "            sys_mean=get_means2(conn_mat,sys_ix,sys_iy)\n",
    "            sys_null_dist=get_null_means2(np.expand_dims(null_mat,axis=0),sys_ix,sys_iy)\n",
    "            sys_z,sys_p=compute_pval_twotail(sys_mean[0],sys_null_dist[0,:])\n",
    "            if print_vals:\n",
    "                print('{} x {} z={}, p={}'.format(sys1,sys2,sys_z,sys_p))\n",
    "            sys_df.loc[sys1,sys2]=sys_mean\n",
    "            sys_df_zvals.loc[sys1,sys2]=sys_z\n",
    "            sys_df_pvals.loc[sys1,sys2]=sys_p\n",
    "            \n",
    "    if thresh:\n",
    "        reject_fdr,pval_fdr=fdr_correction(sys_df_pvals,alpha)\n",
    "        sys_df_zvals_fdr=np.multiply(sys_df_zvals,reject_fdr)\n",
    "        sys_dict={'sys_names':sys_names,\n",
    "                  'sys_df':sys_df,\n",
    "                  'sys_df_zvals':sys_df_zvals,\n",
    "                  'sys_df_zvals_fdr':sys_df_zvals_fdr,\n",
    "                  'sys_df_pvals':sys_df_pvals}\n",
    "    else:\n",
    "        sys_dict={'sys_names':sys_names,\n",
    "                  'sys_df':sys_df,\n",
    "                  'sys_df_zvals':sys_df_zvals,\n",
    "                  'sys_df_pvals':sys_df_pvals}\n",
    "    if plot=='thresh':\n",
    "        ax1=plotting.plot_matrix(sys_df_zvals_fdr,vmin=-4,vmax=4,labels=sys_names,auto_fit=False)\n",
    "        plt.show()\n",
    "    elif plot=='unc':\n",
    "        ax1=plotting.plot_matrix(sys_df_zvals,vmin=-4,vmax=4,labels=sys_names,auto_fit=False)\n",
    "        plt.show()\n",
    "        \n",
    "    return sys_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sys_zscores2(conn_mat,null_mat,syslist,\n",
    "                     plot=True,thresh='fdr',alpha=0.025,print_vals=True):\n",
    "    sys_names=syslist.keys()\n",
    "    sys_names.sort()\n",
    "    n_sys=len(syslist)\n",
    "    sys_df=pd.DataFrame(np.zeros((n_sys,n_sys)))\n",
    "    sys_df.index=sys_names\n",
    "    sys_df.columns=sys_names\n",
    "    sys_df_zvals=sys_df.copy()\n",
    "    sys_df_pvals=sys_df.copy()\n",
    "    \n",
    "    for sys1 in sys_names:\n",
    "        for sys2 in sys_names:\n",
    "            sys_ix=syslist[sys1]\n",
    "            sys_iy=syslist[sys2]\n",
    "            #print('{}: {}'.format(sys1,sys_ix))\n",
    "            #print('{}: {}'.format(sys2,sys_iy))\n",
    "            sys_mean=get_means2(conn_mat,sys_ix,sys_iy)\n",
    "            sys_null_dist=get_null_means2(np.expand_dims(null_mat,axis=0),sys_ix,sys_iy)\n",
    "            sys_z,sys_p=compute_pval_twotail(sys_mean[0],sys_null_dist[0,:])\n",
    "            if print_vals:\n",
    "                print('{} x {} z={}, p={}'.format(sys1,sys2,sys_z,sys_p))\n",
    "            sys_df.loc[sys1,sys2]=sys_mean\n",
    "            sys_df_zvals.loc[sys1,sys2]=sys_z\n",
    "            sys_df_pvals.loc[sys1,sys2]=sys_p\n",
    "\n",
    "    if thresh=='fdr':\n",
    "        reject_fdr,pval_fdr=fdr_correction(sys_df_pvals,alpha)\n",
    "        sys_df_zvals_fdr=np.multiply(sys_df_zvals,reject_fdr)\n",
    "        sys_dict={'sys_names':sys_names,\n",
    "                  'sys_df':sys_df,\n",
    "                  'sys_df_zvals':sys_df_zvals,\n",
    "                  'sys_df_zvals_fdr':sys_df_zvals_fdr,\n",
    "                  'sys_df_pvals':sys_df_pvals}\n",
    "    elif thresh=='unc':\n",
    "        thmat=np.where(sys_df_pvals<alpha,1,0)\n",
    "        sys_df_zvals_unc=np.multiply(sys_df_zvals,thmat)\n",
    "        sys_dict={'sys_names':sys_names,\n",
    "                  'sys_df':sys_df,\n",
    "                  'sys_df_zvals':sys_df_zvals,\n",
    "                  'sys_df_pvals':sys_df_pvals}\n",
    "    \n",
    "    else:\n",
    "        sys_dict={'sys_names':sys_names,\n",
    "                  'sys_df':sys_df,\n",
    "                  'sys_df_zvals':sys_df_zvals,\n",
    "                  'sys_df_pvals':sys_df_pvals}\n",
    "    \n",
    "    if plot=='thresh':\n",
    "        ax1=plotting.plot_matrix(sys_df_zvals_fdr,vmin=-4,vmax=4,labels=sys_names,auto_fit=False)\n",
    "        plt.show()\n",
    "    elif plot=='all':\n",
    "        ax1=plotting.plot_matrix(sys_df_zvals,vmin=-4,vmax=4,labels=sys_names,auto_fit=False)\n",
    "        plt.show()\n",
    "    return sys_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_roihub_dict=get_sys_zscores2(diffMat1,diff_nullMat,syslist_rois2,\n",
    "                                plot=True,thresh='fdr',print_vals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cog_sys_dict=get_sys_zscores(conn_mat=diffMat1,null_mat=diff_nullMat,\n",
    "                                  node_df=schaefer_atlas,sys_names=sch_names,colindex='System',\n",
    "                                  plot='unc',print_vals=True,thresh=True,alpha=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_cog_sys_dict=get_sys_zscores(conn_mat=combMat1,null_mat=comb_nullMat,\n",
    "                                  node_df=schaefer_atlas,sys_names=sch_names,colindex='System',\n",
    "                                  plot='unc',print_vals=True,thresh=True,alpha=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_zscores(dict1,savepath,savename):\n",
    "    np.savez(opj(savepath,savename),\n",
    "             sys_names=dict1['sys_names'],\n",
    "             #sys_df=dict1['sys_df'],\n",
    "             pMat=dict1['sys_df_pvals'],\n",
    "             zMat=dict1['sys_df_zvals'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_path='/Users/steventompson/Git/tompson_netlearn_fmri/data/netLearn_ppi_zscores'\n",
    "\n",
    "save_zscores(diff_roihub_dict,path_OutpData,'netLearn_diffData_zscores_groupavg_roihub_connmat.npz')\n",
    "save_zscores(diff_cog_sys_dict,path_OutpData,'netLearn_diffData_zscores_groupavg_cogsys_connmat.npz')\n",
    "save_zscores(comb_cog_sys_dict,path_OutpData,'netLearn_combData_zscores_groupavg_cogsys_connmat.npz')\n",
    "\n",
    "\n",
    "save_zscores(diff_roihub_dict,git_path,'netLearn_diffData_zscores_groupavg_roihub_connmat.npz')\n",
    "save_zscores(diff_cog_sys_dict,git_path,'netLearn_diffData_zscores_groupavg_cogsys_connmat.npz')\n",
    "save_zscores(comb_cog_sys_dict,git_path,'netLearn_combData_zscores_groupavg_cogsys_connmat.npz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steven Tompson | 2019"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
